{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OcioQr0Y76f"
      },
      "source": [
        "# **Deep Learning Models for Product Categorization**\n",
        "\n",
        "In this notebook, several famous Deep Learning models (like LSTM and some other transformer based models) are trained on the balanced dataset (the one balanced using undersampling technique). These models are then then evaluated with the help of Classification Report, Confusion Matrix, Accuracy Score, etc. All the Deep Learning models are implemented using the **PyTorch** framework owing to its fast computational power.\n",
        "\n",
        "\n",
        "### ***Deep Learning Models Used for training and testing:***\n",
        "1. Tranformer based models like:\n",
        "* BERT\n",
        "* RoBERTa\n",
        "* DistilBERT\n",
        "* XLNet\n",
        "2. LSTM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Or9I16zabtr"
      },
      "source": [
        "## **Installing and Importing the required libraries and reasing the Dataset**\n",
        "\n",
        "Several libraries related to Pytorch and needed for transformer based models are first installed. Other libraries related to Dataframe handling, preparation of the dataset for testing and training, etc are imported. The dataset that was balanced using Undersampling technique in the [first notebook](https://colab.research.google.com/drive/1Ht6pbVFlkudK7PzrDPmepiytHxPyhVBe?usp=sharing) has been used for both testing and training. This dataset consists of only those products which belong to the 13 major categories as described earlier (the data points that correspond to noise have been already removed). This dataset has already been cleaned using the data preprocessing tecniques like stopword removal, tokenization and lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvShb_A6Y9_D",
        "outputId": "6e642eda-4ab5-4ac0-dc51-705ef580e099"
      },
      "source": [
        "!pip install torch==1.7.1\n",
        "!pip install transformers\n",
        "!pip install simpletransformers\n",
        "!pip install tensorboardx\n",
        "!pip install pytorch-nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.1\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: simpletransformers in /usr/local/lib/python3.10/dist-packages (0.70.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (4.66.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2024.5.15)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (4.42.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.20.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.3.2)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.2.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.17.0)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.6.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (2.1.4)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (0.19.1)\n",
            "Requirement already satisfied: wandb>=0.10.32 in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (0.17.5)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (1.37.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from simpletransformers) (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (0.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (6.0.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->simpletransformers) (0.4.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (2.12.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.10.32->simpletransformers) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->simpletransformers) (2024.7.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets->simpletransformers) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->simpletransformers) (3.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->simpletransformers) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->simpletransformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->simpletransformers) (3.5.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit->simpletransformers) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (5.4.0)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (9.4.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (4.12.2)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit->simpletransformers) (4.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (3.6)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->simpletransformers) (3.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->simpletransformers) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.11)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.2)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (3.20.3)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-nlp) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-nlp) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3p52NUHl1D1",
        "outputId": "53ebf661-5baf-449e-f375-5df9fdbe94fc"
      },
      "source": [
        "# importing the libraries involved in matrix operations and dataframe handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# importing libraries related to NLTK, vectorizers and string processing\n",
        "import nltk\n",
        "import string\n",
        "nltk.download(\"all\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# other miscellaneous libraries used while preparing data for testing and evaluation\n",
        "from collections import Counter\n",
        "import re\n",
        "from sys import maxsize\n",
        "import random\n",
        "import timeit\n",
        "import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nJv_kR7Qacd",
        "outputId": "1f69fec5-f153-4013-a1ac-1708042c191f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_BDY7yVcaVb"
      },
      "source": [
        "## **PART 1) Transformer Based Models:**\n",
        "\n",
        "In the first part of the notebook Transformer based models like BERT and its variants like DistilBERT, RoBERTa and XLNet are trained and tested."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW62yz8KdJlr"
      },
      "source": [
        "## **1) Training and Testing the Bidirectional Encoder Representations from Transformers (BERT) model**\n",
        "\n",
        "The first transformer based model that is trained is BERT. BERT has shown amazing results in the field of NLP for several tasks like text classification, question answering, etc and hence, it was decided to try BERT as well to solve our problem of Product Categorization (Multiclass Classification)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZEGkfnAMpFJE",
        "outputId": "c7f9e4dd-7a12-4ccd-f609-bc954044f7f3"
      },
      "source": [
        "balanced_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/undersampling_balanced_products.csv\")\n",
        "balanced_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                           uniq_id  \\\n",
              "10550       10550  a2f14c69402bf2508cc7f9ddeccc4bd1   \n",
              "349           349  9d442ef603d3149cf53c95d9b4cb490f   \n",
              "5518         5518  cb0afa31d9ca796908fde019cd64044d   \n",
              "5377         5377  9f1fc799de37a3325900ea892494af51   \n",
              "11220       11220  4fbc3935a634aa2dec2676641d52fcab   \n",
              "7234         7234  544e9220edf5182b62dd8d955d347784   \n",
              "6845         6845  41c459b3b531aa0b725155a97e429b85   \n",
              "13105       13105  c41e4520b3daaf2edd11f80234bb28fd   \n",
              "12330       12330  6933454b58d77d4ab74168389c9c5d60   \n",
              "6484         6484  a8293602876a2c65520a61c127522f77   \n",
              "\n",
              "                 crawl_timestamp  \\\n",
              "10550  2015-12-30 00:17:46 +0000   \n",
              "349    2016-01-06 18:20:45 +0000   \n",
              "5518   2015-12-01 06:13:00 +0000   \n",
              "5377   2015-12-01 06:13:00 +0000   \n",
              "11220  2015-12-30 00:17:46 +0000   \n",
              "7234   2016-04-16 13:01:18 +0000   \n",
              "6845   2016-03-05 04:18:53 +0000   \n",
              "13105  2015-12-12 11:46:53 +0000   \n",
              "12330  2015-12-13 00:29:55 +0000   \n",
              "6484   2015-12-01 06:13:00 +0000   \n",
              "\n",
              "                                             product_url  \\\n",
              "10550  http://www.flipkart.com/vama-fashions-alloy-cu...   \n",
              "349    http://www.flipkart.com/bluestone-princess-gol...   \n",
              "5518   http://www.flipkart.com/asus-rt-ac68u-dual-ban...   \n",
              "5377   http://www.flipkart.com/modx-steering-cover-hy...   \n",
              "11220  http://www.flipkart.com/eves-pret-porter-women...   \n",
              "7234   http://www.flipkart.com/emagica-home-security-...   \n",
              "6845   http://www.flipkart.com/kits-kart-pouch-intex-...   \n",
              "13105  http://www.flipkart.com/my-foot-women-wedges/p...   \n",
              "12330  http://www.flipkart.com/ocean-race-graphic-pri...   \n",
              "6484   http://www.flipkart.com/espoir-alloy-necklace/...   \n",
              "\n",
              "                                            product_name  \\\n",
              "10550  Viva Fashions Alloy Cubic Zirconia Rhodium Bangle   \n",
              "349        BlueStone The Princess Gold Diamond 18 K Ring   \n",
              "5518   Asus RT-AC68U Dual-band Wireless-AC1900 Gigabi...   \n",
              "5377                 Modx Steering Cover For Hyundai i10   \n",
              "11220      Eves Pret A Porter Women's Solid Casual Shirt   \n",
              "7234   Emagica Home Security 1 Channel Home Security ...   \n",
              "6845              kits kart Pouch for Intex Aqua i5 Mini   \n",
              "13105                               My Foot Women Wedges   \n",
              "12330  Ocean Race Graphic Print Men's Round Neck T-Shirt   \n",
              "6484                               Espoir Alloy Necklace   \n",
              "\n",
              "        product_category_tree               pid  retail_price  \\\n",
              "10550              Jewellery   BBAEDZHYZZQHYEHU         900.0   \n",
              "349                Jewellery   RNGDQ5GGSFNHNANZ       35415.0   \n",
              "5518               Computers   RTRDRDPR9JHCSBGH       25000.0   \n",
              "5377              Automotive   CSOE88UGU7GZPNZS         549.0   \n",
              "11220               Clothing   SHTE9KP2PGR2MPHM        1200.0   \n",
              "7234       Pens & Stationery   HSAEGZAV4UGWJAAH        3590.0   \n",
              "6845   Mobiles & Accessories   ACCEGH6RPWY9DHAB         908.0   \n",
              "13105               Footwear   SNDEAN42PCMFHQAR        1599.0   \n",
              "12330               Clothing   TSHE9K9GCGK6GRB5         598.0   \n",
              "6484               Jewellery   NKCE6Y3M64RTXY2F         999.0   \n",
              "\n",
              "       discounted_price                                              image  \\\n",
              "10550             900.0  [\"http://img6a.flixcart.com/image/bangle-brace...   \n",
              "349             26984.0  [\"http://img5a.flixcart.com/image/ring/w/z/v/5...   \n",
              "5518            13390.0  [\"http://img6a.flixcart.com/image/router/b/g/h...   \n",
              "5377              477.0  [\"http://img5a.flixcart.com/image/car-steering...   \n",
              "11220             399.0  [\"http://img6a.flixcart.com/image/shirt/g/s/7/...   \n",
              "7234             2420.0  [\"http://img5a.flixcart.com/image/home-securit...   \n",
              "6845              454.0  [\"http://img5a.flixcart.com/image/cases-covers...   \n",
              "13105             956.0  [\"http://img5a.flixcart.com/image/sandal/c/z/q...   \n",
              "12330             299.0  [\"http://img6a.flixcart.com/image/t-shirt/r/b/...   \n",
              "6484              399.0  [\"http://img5a.flixcart.com/image/pendant-lock...   \n",
              "\n",
              "       ...                                        description  \\\n",
              "10550  ...  Viva Fashions Alloy Cubic Zirconia Rhodium Ban...   \n",
              "349    ...  BlueStone The Princess Gold Diamond 18 K Ring ...   \n",
              "5518   ...  Buy Asus RT-AC68U Dual-band Wireless-AC1900 Gi...   \n",
              "5377   ...  Buy Modx Steering Cover For Hyundai i10 for Rs...   \n",
              "11220  ...  Eves Pret A Porter Women's Solid Casual Shirt ...   \n",
              "7234   ...  Key Features of Emagica Home Security 1 Channe...   \n",
              "6845   ...  Key Features of kits kart Pouch for Intex Aqua...   \n",
              "13105  ...  Flipkart.com: Buy My Foot Women Wedges only fo...   \n",
              "12330  ...  Ocean Race Graphic Print Men's Round Neck T-Sh...   \n",
              "6484   ...  Espoir Alloy Necklace - Buy Espoir Alloy Neckl...   \n",
              "\n",
              "            product_rating       overall_rating          brand  \\\n",
              "10550  No rating available  No rating available  Viva Fashions   \n",
              "349    No rating available  No rating available      BlueStone   \n",
              "5518                   4.3                  4.3           Asus   \n",
              "5377   No rating available  No rating available           Modx   \n",
              "11220  No rating available  No rating available           Slim   \n",
              "7234   No rating available  No rating available        Emagica   \n",
              "6845   No rating available  No rating available      kits kart   \n",
              "13105  No rating available  No rating available            NaN   \n",
              "12330  No rating available  No rating available            NaN   \n",
              "6484   No rating available  No rating available         Espoir   \n",
              "\n",
              "                                  product_specifications   primary_categories  \\\n",
              "10550  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...            jewellery   \n",
              "349    {\"product_specification\"=>[{\"key\"=>\"Pack of\", ...            jewellery   \n",
              "5518   {\"product_specification\"=>[{\"key\"=>\"In The Box...          electronics   \n",
              "5377   {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...           automotive   \n",
              "11220  {\"product_specification\"=>[{\"key\"=>\"Pattern\", ...             clothing   \n",
              "7234   {\"product_specification\"=>[{\"value\"=>\"1 Home S...  toys&schoolsupplies   \n",
              "6845   {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...          electronics   \n",
              "13105  {\"product_specification\"=>[{\"key\"=>\"Ideal For\"...             footwear   \n",
              "12330  {\"product_specification\"=>[{\"key\"=>\"Sleeve\", \"...             clothing   \n",
              "6484   {\"product_specification\"=>[{\"key\"=>\"Collection...            jewellery   \n",
              "\n",
              "      main_category      desc_pol  desc_len  \\\n",
              "10550             1  2.250000e-01     227.0   \n",
              "349               1  2.250000e-01     219.0   \n",
              "5518              1  2.250000e-01     182.0   \n",
              "5377              1  4.500000e-01     201.0   \n",
              "11220             1 -7.500000e-02     220.0   \n",
              "7234              1  1.572055e-01    1632.0   \n",
              "6845              1  1.361527e-01    1678.0   \n",
              "13105             1  2.250000e-01     160.0   \n",
              "12330             1  7.930164e-18     226.0   \n",
              "6484              1  2.250000e-01     171.0   \n",
              "\n",
              "                                            cleaned_desc  \n",
              "10550  viva fashions alloy cubic zirconia rhodium ban...  \n",
              "349    bluestone the princess gold diamond 18 k ring ...  \n",
              "5518   buy asus rt-ac68u dual-band wireless-ac1900 gi...  \n",
              "5377   buy modx steering cover for hyundai i10 for rs...  \n",
              "11220  eves pret a porter women's solid casual shirt ...  \n",
              "7234   key features of emagica home security 1 channe...  \n",
              "6845   key features of kits kart pouch for intex aqua...  \n",
              "13105  flipkart.com: buy my foot women wedges only fo...  \n",
              "12330  ocean race graphic print men's round neck t-sh...  \n",
              "6484   espoir alloy necklace - buy espoir alloy neckl...  \n",
              "\n",
              "[10 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-317f3d49-417e-4e8a-b2e5-0a892d948a59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>uniq_id</th>\n",
              "      <th>crawl_timestamp</th>\n",
              "      <th>product_url</th>\n",
              "      <th>product_name</th>\n",
              "      <th>product_category_tree</th>\n",
              "      <th>pid</th>\n",
              "      <th>retail_price</th>\n",
              "      <th>discounted_price</th>\n",
              "      <th>image</th>\n",
              "      <th>...</th>\n",
              "      <th>description</th>\n",
              "      <th>product_rating</th>\n",
              "      <th>overall_rating</th>\n",
              "      <th>brand</th>\n",
              "      <th>product_specifications</th>\n",
              "      <th>primary_categories</th>\n",
              "      <th>main_category</th>\n",
              "      <th>desc_pol</th>\n",
              "      <th>desc_len</th>\n",
              "      <th>cleaned_desc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10550</th>\n",
              "      <td>10550</td>\n",
              "      <td>a2f14c69402bf2508cc7f9ddeccc4bd1</td>\n",
              "      <td>2015-12-30 00:17:46 +0000</td>\n",
              "      <td>http://www.flipkart.com/vama-fashions-alloy-cu...</td>\n",
              "      <td>Viva Fashions Alloy Cubic Zirconia Rhodium Bangle</td>\n",
              "      <td>Jewellery</td>\n",
              "      <td>BBAEDZHYZZQHYEHU</td>\n",
              "      <td>900.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>[\"http://img6a.flixcart.com/image/bangle-brace...</td>\n",
              "      <td>...</td>\n",
              "      <td>Viva Fashions Alloy Cubic Zirconia Rhodium Ban...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>Viva Fashions</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
              "      <td>jewellery</td>\n",
              "      <td>1</td>\n",
              "      <td>2.250000e-01</td>\n",
              "      <td>227.0</td>\n",
              "      <td>viva fashions alloy cubic zirconia rhodium ban...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>349</td>\n",
              "      <td>9d442ef603d3149cf53c95d9b4cb490f</td>\n",
              "      <td>2016-01-06 18:20:45 +0000</td>\n",
              "      <td>http://www.flipkart.com/bluestone-princess-gol...</td>\n",
              "      <td>BlueStone The Princess Gold Diamond 18 K Ring</td>\n",
              "      <td>Jewellery</td>\n",
              "      <td>RNGDQ5GGSFNHNANZ</td>\n",
              "      <td>35415.0</td>\n",
              "      <td>26984.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/ring/w/z/v/5...</td>\n",
              "      <td>...</td>\n",
              "      <td>BlueStone The Princess Gold Diamond 18 K Ring ...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>BlueStone</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Pack of\", ...</td>\n",
              "      <td>jewellery</td>\n",
              "      <td>1</td>\n",
              "      <td>2.250000e-01</td>\n",
              "      <td>219.0</td>\n",
              "      <td>bluestone the princess gold diamond 18 k ring ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5518</th>\n",
              "      <td>5518</td>\n",
              "      <td>cb0afa31d9ca796908fde019cd64044d</td>\n",
              "      <td>2015-12-01 06:13:00 +0000</td>\n",
              "      <td>http://www.flipkart.com/asus-rt-ac68u-dual-ban...</td>\n",
              "      <td>Asus RT-AC68U Dual-band Wireless-AC1900 Gigabi...</td>\n",
              "      <td>Computers</td>\n",
              "      <td>RTRDRDPR9JHCSBGH</td>\n",
              "      <td>25000.0</td>\n",
              "      <td>13390.0</td>\n",
              "      <td>[\"http://img6a.flixcart.com/image/router/b/g/h...</td>\n",
              "      <td>...</td>\n",
              "      <td>Buy Asus RT-AC68U Dual-band Wireless-AC1900 Gi...</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.3</td>\n",
              "      <td>Asus</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"In The Box...</td>\n",
              "      <td>electronics</td>\n",
              "      <td>1</td>\n",
              "      <td>2.250000e-01</td>\n",
              "      <td>182.0</td>\n",
              "      <td>buy asus rt-ac68u dual-band wireless-ac1900 gi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5377</th>\n",
              "      <td>5377</td>\n",
              "      <td>9f1fc799de37a3325900ea892494af51</td>\n",
              "      <td>2015-12-01 06:13:00 +0000</td>\n",
              "      <td>http://www.flipkart.com/modx-steering-cover-hy...</td>\n",
              "      <td>Modx Steering Cover For Hyundai i10</td>\n",
              "      <td>Automotive</td>\n",
              "      <td>CSOE88UGU7GZPNZS</td>\n",
              "      <td>549.0</td>\n",
              "      <td>477.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/car-steering...</td>\n",
              "      <td>...</td>\n",
              "      <td>Buy Modx Steering Cover For Hyundai i10 for Rs...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>Modx</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
              "      <td>automotive</td>\n",
              "      <td>1</td>\n",
              "      <td>4.500000e-01</td>\n",
              "      <td>201.0</td>\n",
              "      <td>buy modx steering cover for hyundai i10 for rs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11220</th>\n",
              "      <td>11220</td>\n",
              "      <td>4fbc3935a634aa2dec2676641d52fcab</td>\n",
              "      <td>2015-12-30 00:17:46 +0000</td>\n",
              "      <td>http://www.flipkart.com/eves-pret-porter-women...</td>\n",
              "      <td>Eves Pret A Porter Women's Solid Casual Shirt</td>\n",
              "      <td>Clothing</td>\n",
              "      <td>SHTE9KP2PGR2MPHM</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>399.0</td>\n",
              "      <td>[\"http://img6a.flixcart.com/image/shirt/g/s/7/...</td>\n",
              "      <td>...</td>\n",
              "      <td>Eves Pret A Porter Women's Solid Casual Shirt ...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>Slim</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Pattern\", ...</td>\n",
              "      <td>clothing</td>\n",
              "      <td>1</td>\n",
              "      <td>-7.500000e-02</td>\n",
              "      <td>220.0</td>\n",
              "      <td>eves pret a porter women's solid casual shirt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7234</th>\n",
              "      <td>7234</td>\n",
              "      <td>544e9220edf5182b62dd8d955d347784</td>\n",
              "      <td>2016-04-16 13:01:18 +0000</td>\n",
              "      <td>http://www.flipkart.com/emagica-home-security-...</td>\n",
              "      <td>Emagica Home Security 1 Channel Home Security ...</td>\n",
              "      <td>Pens &amp; Stationery</td>\n",
              "      <td>HSAEGZAV4UGWJAAH</td>\n",
              "      <td>3590.0</td>\n",
              "      <td>2420.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/home-securit...</td>\n",
              "      <td>...</td>\n",
              "      <td>Key Features of Emagica Home Security 1 Channe...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>Emagica</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"value\"=&gt;\"1 Home S...</td>\n",
              "      <td>toys&amp;schoolsupplies</td>\n",
              "      <td>1</td>\n",
              "      <td>1.572055e-01</td>\n",
              "      <td>1632.0</td>\n",
              "      <td>key features of emagica home security 1 channe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>6845</td>\n",
              "      <td>41c459b3b531aa0b725155a97e429b85</td>\n",
              "      <td>2016-03-05 04:18:53 +0000</td>\n",
              "      <td>http://www.flipkart.com/kits-kart-pouch-intex-...</td>\n",
              "      <td>kits kart Pouch for Intex Aqua i5 Mini</td>\n",
              "      <td>Mobiles &amp; Accessories</td>\n",
              "      <td>ACCEGH6RPWY9DHAB</td>\n",
              "      <td>908.0</td>\n",
              "      <td>454.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/cases-covers...</td>\n",
              "      <td>...</td>\n",
              "      <td>Key Features of kits kart Pouch for Intex Aqua...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>kits kart</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
              "      <td>electronics</td>\n",
              "      <td>1</td>\n",
              "      <td>1.361527e-01</td>\n",
              "      <td>1678.0</td>\n",
              "      <td>key features of kits kart pouch for intex aqua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13105</th>\n",
              "      <td>13105</td>\n",
              "      <td>c41e4520b3daaf2edd11f80234bb28fd</td>\n",
              "      <td>2015-12-12 11:46:53 +0000</td>\n",
              "      <td>http://www.flipkart.com/my-foot-women-wedges/p...</td>\n",
              "      <td>My Foot Women Wedges</td>\n",
              "      <td>Footwear</td>\n",
              "      <td>SNDEAN42PCMFHQAR</td>\n",
              "      <td>1599.0</td>\n",
              "      <td>956.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/sandal/c/z/q...</td>\n",
              "      <td>...</td>\n",
              "      <td>Flipkart.com: Buy My Foot Women Wedges only fo...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Ideal For\"...</td>\n",
              "      <td>footwear</td>\n",
              "      <td>1</td>\n",
              "      <td>2.250000e-01</td>\n",
              "      <td>160.0</td>\n",
              "      <td>flipkart.com: buy my foot women wedges only fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12330</th>\n",
              "      <td>12330</td>\n",
              "      <td>6933454b58d77d4ab74168389c9c5d60</td>\n",
              "      <td>2015-12-13 00:29:55 +0000</td>\n",
              "      <td>http://www.flipkart.com/ocean-race-graphic-pri...</td>\n",
              "      <td>Ocean Race Graphic Print Men's Round Neck T-Shirt</td>\n",
              "      <td>Clothing</td>\n",
              "      <td>TSHE9K9GCGK6GRB5</td>\n",
              "      <td>598.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>[\"http://img6a.flixcart.com/image/t-shirt/r/b/...</td>\n",
              "      <td>...</td>\n",
              "      <td>Ocean Race Graphic Print Men's Round Neck T-Sh...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Sleeve\", \"...</td>\n",
              "      <td>clothing</td>\n",
              "      <td>1</td>\n",
              "      <td>7.930164e-18</td>\n",
              "      <td>226.0</td>\n",
              "      <td>ocean race graphic print men's round neck t-sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6484</th>\n",
              "      <td>6484</td>\n",
              "      <td>a8293602876a2c65520a61c127522f77</td>\n",
              "      <td>2015-12-01 06:13:00 +0000</td>\n",
              "      <td>http://www.flipkart.com/espoir-alloy-necklace/...</td>\n",
              "      <td>Espoir Alloy Necklace</td>\n",
              "      <td>Jewellery</td>\n",
              "      <td>NKCE6Y3M64RTXY2F</td>\n",
              "      <td>999.0</td>\n",
              "      <td>399.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/pendant-lock...</td>\n",
              "      <td>...</td>\n",
              "      <td>Espoir Alloy Necklace - Buy Espoir Alloy Neckl...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>Espoir</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Collection...</td>\n",
              "      <td>jewellery</td>\n",
              "      <td>1</td>\n",
              "      <td>2.250000e-01</td>\n",
              "      <td>171.0</td>\n",
              "      <td>espoir alloy necklace - buy espoir alloy neckl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows  21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-317f3d49-417e-4e8a-b2e5-0a892d948a59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-317f3d49-417e-4e8a-b2e5-0a892d948a59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-317f3d49-417e-4e8a-b2e5-0a892d948a59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-31e7ea34-5951-434c-8380-a4474eba0c8f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31e7ea34-5951-434c-8380-a4474eba0c8f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-31e7ea34-5951-434c-8380-a4474eba0c8f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehOx80BVc0gb",
        "outputId": "fc6992b6-a3dc-4638-8204-5f7be967aa78"
      },
      "source": [
        "balanced_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14999, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5b8wkuuRIkU",
        "outputId": "f9effcb9-c6b2-40b2-c751-b7f65568e47b"
      },
      "source": [
        "#printing all the 13 major categories and the frequency of their products in the dataset\n",
        "Counter(balanced_df['primary_categories'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'clothing': 5316,\n",
              "         'footwear': 1083,\n",
              "         'toys&schoolsupplies': 535,\n",
              "         'personalaccessories': 684,\n",
              "         'homefurnishing/kitchen': 1324,\n",
              "         'automotive': 937,\n",
              "         'tools&hardware': 379,\n",
              "         'babycare': 224,\n",
              "         'electronics': 1299,\n",
              "         'jewellery': 3218})"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0tUoEpKdFOc"
      },
      "source": [
        "## **Splitting the dataset into Training and Testing Dataframes**\n",
        "\n",
        "The dataset has been split in the initial stages only into training and testing dataframes using the train_test_split function available in sci-kit learn package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZoAhadRXzfv",
        "outputId": "ea97c476-cf6b-4072-958c-f8d70443ef51"
      },
      "source": [
        "#splitting the dataframe into test and training dataframe\n",
        "\n",
        "balanced_df, test_df = train_test_split(balanced_df, test_size=0.1, random_state = 2018)\n",
        "print(balanced_df.shape, test_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13499, 21) (1500, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VomNqt3efg6"
      },
      "source": [
        "### **The GPU provided by Google Colab has been used for Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfAo3-_FSZ89",
        "outputId": "dae31cd5-7c2e-4338-a86c-461d9d237d43"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5jBAwbLesjt"
      },
      "source": [
        "## **Encoding the Product Categories**\n",
        "\n",
        "Encoding of the 13 Product Categories is done using LabelEncoder. This is done so because the string categories cannot be directly passed into the model and hence, they have to be represented in a numerical format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEar_FZeUo_9",
        "outputId": "599202db-372f-4a13-8a8a-2af9e43019d4"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "balanced_df['categories']=encoder.fit_transform(balanced_df['primary_categories'])\n",
        "print(Counter(balanced_df['categories']))\n",
        "\n",
        "prediction_decoded = encoder.inverse_transform(balanced_df['categories'])\n",
        "print(Counter(prediction_decoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({2: 4771, 6: 2902, 5: 1173, 3: 1169, 4: 969, 0: 853, 7: 628, 9: 491, 8: 342, 1: 201})\n",
            "Counter({'clothing': 4771, 'jewellery': 2902, 'homefurnishing/kitchen': 1173, 'electronics': 1169, 'footwear': 969, 'automotive': 853, 'personalaccessories': 628, 'toys&schoolsupplies': 491, 'tools&hardware': 342, 'babycare': 201})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOTFWmhbVNXU"
      },
      "source": [
        "## **BERT Specific Tokenization & Input Formatting**\n",
        "\n",
        "As BERT model requires some specific tokens and input formattings, BertTokenizer has been installed for the same. In this notebook, we have used the **'uncased'** version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4cy5AvSm9sI",
        "outputId": "6bf511ae-5935-4ad2-d7b7-fe3955475f67"
      },
      "source": [
        "#loading the BERT tokenizer\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uxTKLa7fmpl"
      },
      "source": [
        "## **Manipulating the data according to the required Input formatting**\n",
        "\n",
        "The input format required by BERT asks us to add special tokens to the start and end of the sentence, pad and truncate all the sentences to a specific constant length and differentiate the pads from tokens by using attention masks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOCkZY_vWJcK"
      },
      "source": [
        "### **To get an idea about the length of the description and its corresponding frequency**\n",
        "\n",
        "As we have to explicitly pad and truncate all the sentences to a fixed constant length, visualisation of the text length of the cleaned and pre processed data is done in order to select a value that is as close to the actual value (so that we do not lose useful information)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desc = balanced_df[\"cleaned_desc\"].tolist()\n",
        "\n",
        "# Handle potential float values in 'desc'\n",
        "seq_len = [len(str(i).split()) if not isinstance(i, float) else 0 for i in desc]\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "xsG-RqNBntWr",
        "outputId": "9af4dd83-1cae-4934-9819-98541cc2aedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 231
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/0AAAIGCAYAAAAGHe8OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOaElEQVR4nO3de3jU5Z338c9MMkmAJJAACYQAUSAEeIpUjl1dthyUuHXroV6gq1gEpSU8PiKo1aJeFR+U1hZl6wVyWDmtCHigoF0CpQHWFREIpyVAFUwIkBhAyIEkJJOZ3/MHz0wZZwLkwCRz5/26Li7C777v+f5G5uvwmfkdbJZlWQIAAAAAAMaxN/UOAAAAAACAG4PQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYKrypd8AElmXJ7baaejeui91uC5l9BW4U+gAtHT0A0AeARB+EMrvdJpvNdl1zCf2NwO22dP58eVPvxjWFh9sVF9dGpaUVqqlxN/XuAE2CPkBLRw8A9AEg0QehLj6+jcLCri/0c3g/AAAAAACGIvQDAAAAAGAoQj8AAAAAAIYi9AMAAAAAYChCPwAAAAAAhiL0AwAAAABgKEI/AAAAAACGIvQDAAAAAGAoQj8AAAAAAIYi9AMAAAAAYChCPwAAAAAAhiL0AwAAAABgKEI/AAAAAACGIvQDAAAAAGAoQj8AAAAAAIYi9AMAAAAAYChCPwAAAAAAhgqv64JTp05p1KhR1zX3/vvv1+uvv+6zzel0avny5dqwYYPy8/PlcDiUlpam8ePH684777zq4x0+fFiLFi3S7t27VVpaqoSEBI0YMUIZGRmKj4+vdV1DagIAAAAAEKrqHPojIyN166231jpeVVWlnJwcSdIPf/hDv7HHHntM2dnZCgsLU8+ePVVZWaldu3Zp165deuKJJ/TMM88EfNzNmzdr+vTpcjqdat++vXr16qXc3FytXLlSmZmZev/999W1a9eA+1PfmgAAAAAAhLI6h/6OHTvq/fffr3V83bp1ev755xUVFaV//ud/9hl74403lJ2dreTkZC1evFg333yzJOmvf/2rpk2bpsWLF+vWW2/VyJEjfdYVFRXpueeek9PpVEZGhqZOnarw8HCVlZXp6aef1meffaZp06bpww8/lM1ma5SaaBx2u012u+3aExuJ223J7baCVg8AAAAAmrNGP6f/448/liTdcccdio6O9m4/d+6cVq9eLUmaPXu2N3xL0qhRo/T4449Lkt5++22/x1yyZIkqKys1ePBgPfXUUwoPv/xZRUxMjP7whz8oJiZGhw4d0tatW33WNaQmGs5ut6ldu9aKi2sTtF/t2rUO6ocMAAAAANCc1fmb/qs5deqUdu/eLeny+fxXysrKktPpVEpKioYNG+a39sEHH9T8+fOVk5Oj/Px8devWzTu2adMmSdLYsWP91rVt21bp6en64IMPtHHjRp9v7BtSEw1nt9sUFmbX79/L1qmishteLzkxRs88PFB2u41v+wEAAABAjRz6//SnP8myLCUlJfmF7P3790uSBg4cGHBtYmKikpOTderUKe3fv98bwAsLC1VUVCRJGjx4cMC1gwYN0gcffKADBw40Sk00rlNFZTp+uqSpdwMAAAAAWpxGO7zfsiytW7dOknTPPffIbvd96Ly8PEm6arD2jOXm5vqtczgc6tSpU8B1ngv4nTx5Uk6ns8E1AQAAAAAwQaN9079r1y6dOnVKkv+h/ZJUUnL5m962bdvW+hiesdLSUu+24uJi79j3L9Ln0a5dO0mS2+3WxYsXFRcX16Ca9REe3uiXR2h0YWF2n9+DVS/YmqouQkOw+wBobugBgD4AJPqgJWm00O/5ln/QoEEBv1mvqqqSdPkb+9pERERIki5dulSvdVfOb0jNurLbbYqLa1Pv9cEWG9uqqXfhhjL9+aFx8DpBS0cPAPQBINEHLUGjhP7y8nLvxfbuu+++gHMiIyMlyefw+++rrq6WJEVFRdVr3ZXzG1KzrtxuS6WlFfVeHyxhYXbFxrZSaWmlXC530OoFW7CeH0JTsPsAaG7oAYA+ACT6INTFxra67qM0GiX0b9q0SRUVFWrVqpXS09Nr2alYSX8/5D4Qz5hnrvT3w+9LSkpkWVbAQ/w9pwDY7Xaf2wTWt2Z91NSETqO4XO6Q2t+6Mv35oXHwOkFLRw8A9AEg0QctQaOcwOE5tH/MmDE+oftKKSkpkqQTJ07U+jj5+fk+c6/82el0qrCwMOC6kydPSpKSk5N9DuWvb00AAAAAAEzQ4NB/8uRJ7d69W1Lth/ZL0oABAyRJe/fuDTheVFTkvRCgZ64kJSUlKSEhQZK0Z8+egGs9269c15CaAAAAAACYoMGh/09/+pMsy1KXLl00dOjQWueNGjVKDodDeXl52rlzp9/46tWrJUl9+/ZV9+7dfcbGjBkjSVq7dq3fupKSEmVmZkqS36kFDakJAAAAAECoa1DotyxLf/rTnyRd/pa/tlvqSVKHDh00btw4SdLMmTP1zTffeMeysrK0ZMkSSdLUqVP91k6aNElRUVHavXu35s2bJ5fLJUkqKyvTjBkzVFZWpr59+2rkyJGNVhMAAAAAgFDXoAv57dq1S6dOnZLNZtO99957zfnPPvuscnJytG/fPt19993q1auXKioqvOfVT5w4UaNHj/Zb17lzZ/32t7/VjBkzNH/+fK1Zs0adOnVSbm6uKioq1KFDB7311lsBP3Sob00AAAAAAEJdg0K/5wJ+gwcPVteuXa85PyoqSitWrNCyZcv0ySefKC8vTw6HQ0OGDNEjjzziPYw/kPT0dHXt2lULFy7Unj179NVXXykhIUH333+/MjIy1L59+0avCQAAAABAKLNZlmU19U6EOpfLrfPny5t6N64pPNyuuLg2unChPCi35fDUmzZ3m46frv22iY2lR5e2emv6j4P2/BCagt0HQHNDDwD0ASDRB6EuPr6NwsKu72z9RrllHwAAAAAAaH4I/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGCq8oQ+wfft2ffDBB9q/f7+Ki4vVtm1bde3aVUOHDtWTTz6p8HDfEk6nU8uXL9eGDRuUn58vh8OhtLQ0jR8/XnfeeedVax0+fFiLFi3S7t27VVpaqoSEBI0YMUIZGRmKj4+vdV1DagIAAAAAEKrqHfpramr0wgsvaMOGDZKkzp07Ky0tTcXFxTp06JD27dunyZMn+4T+qqoqPfbYY8rOzlZYWJh69uypyspK7dq1S7t27dITTzyhZ555JmC9zZs3a/r06XI6nWrfvr169eql3NxcrVy5UpmZmXr//ffVtWtXv3UNqQkAAAAAQCird+j/zW9+ow0bNugHP/iBZs2apb59+3rHKisrtWPHDkVERPiseeONN5Sdna3k5GQtXrxYN998syTpr3/9q6ZNm6bFixfr1ltv1ciRI33WFRUV6bnnnpPT6VRGRoamTp2q8PBwlZWV6emnn9Znn32madOm6cMPP5TNZmuUmgAAAAAAhLp6ndO/c+dOffDBB+rSpYuWLVvmE/glqVWrVho1apQcDod327lz57R69WpJ0uzZs73hW5JGjRqlxx9/XJL09ttv+9VbsmSJKisrNXjwYD311FPeowdiYmL0hz/8QTExMTp06JC2bt3qs64hNQEAAAAACHX1Cv1Lly6VJE2cOFHR0dHXtSYrK0tOp1MpKSkaNmyY3/iDDz4oScrJyVF+fr7P2KZNmyRJY8eO9VvXtm1bpaenS5I2btzYaDUBAAAAAAh1dQ79VVVV+vzzzyVJP/rRj3Ts2DHNnj1bEydO1C9/+UvNmzdPp0+f9lu3f/9+SdLAgQMDPm5iYqKSk5N95kpSYWGhioqKJEmDBw8OuHbQoEGSpAMHDjRKTQAAAAAATFDn0H/06FE5nU5JUnZ2tu69916tWLFCn3/+ubZu3ar58+crPT1dn376qc+6vLw8SVK3bt1qfWzPWG5urt86h8OhTp06BVznuYDfyZMnvfvWkJoAAAAAAJigzhfyO3v2rPdnzwX8XnzxRaWlpamwsFBvvvmmNm7cqOeff14333yz93z/kpISSZcPx6+NZ6y0tNS7rbi42Dv2/Yv0ebRr106S5Ha7dfHiRcXFxTWoZn2Eh9frTImgCguz+/werHrB1lR1ERqC3QdAc0MPAPQBINEHLUmdQ395ebn356ioKC1evNgbnLt37665c+cqLy9PR44c0TvvvKN/+7d/k3T5tABJPhf3+z7P1f4vXbrk3VaXdVfOb0jNurLbbYqLa1Pv9cEWG9uqqXfhhjL9+aFx8DpBS0cPAPQBINEHLUGdQ39kZKT35/vuu8/vW3S73a4JEyboV7/6lf77v/9bbrdbdrvdu+7Kw++/r7q6WtLlDxO+X+961n1//+pbs67cbkulpRX1Xh8sYWF2xca2UmlppVwud9DqBVuwnh9CU7D7AGhu6AGAPgAk+iDUxca2uu6jNOoc+q8M+T169Ag4x3NrvPLychUXFys+Pl6xsbGS/n7IfSCeMc/cK+uVlJTIsqyAh/h7TgGw2+0+dxOob836qKkJnUZxudwhtb91ZfrzQ+PgdYKWjh4A6ANAog9agjqfwHHlve5rO2z+ym/b3e7LL6CUlBRJ0okTJ2p9bM9t8zxzr/zZ6XSqsLAw4LqTJ09KkpKTk332qb41AQAAAAAwQZ1Df2Jiorp06SLp72H7+zzbIyMjvRfZGzBggCRp7969AdcUFRXp1KlTPnMlKSkpSQkJCZKkPXv2BFzr2X7luobUBAAAAADABPW6VONdd90lSfrkk09UU1PjN/7hhx9KkgYPHqzw8MtnEIwaNUoOh0N5eXnauXOn35rVq1dLkvr27avu3bv7jI0ZM0aStHbtWr91JSUlyszMlCSlp6f7jDWkJgAAAAAAoa5eoX/SpEmKiYnRqVOnNGvWLO9V8i3L0ooVK7R161bZbDZNnjzZu6ZDhw4aN26cJGnmzJn65ptvvGNZWVlasmSJJGnq1KkB60VFRWn37t2aN2+eXC6XJKmsrEwzZsxQWVmZ+vbtq5EjR/qsa0hNAAAAAABCnc2yLKs+C3fs2KEpU6bo0qVLiomJUUpKir799ludPXtWNptNzz77rCZNmuSz5tKlS5owYYL27dunsLAw9erVSxUVFd7z6idOnKhf/epXAetlZmZqxowZqqmpUfv27dWpUyfl5uaqoqJCHTp00KpVqwJ+W9+QmtfL5XLr/Pnya09sYuHhdsXFtdGFC+VBuViHp960udt0/HTtF1NsLD26tNVb038ctOeH0BTsPgCaG3oAoA8AiT4IdfHxbW7c1fs9/uEf/kHr16/XwoULtWPHDh09elTR0dEaOXKkHnvsMQ0ZMsRvTVRUlFasWKFly5bpk08+UV5enhwOh4YMGaJHHnnEexh/IOnp6eratasWLlyoPXv26KuvvlJCQoLuv/9+ZWRkqH379gHXNaQmAAAAAAChrN7f9OPv+Kb/6vX4ph/NCZ9qo6WjBwD6AJDog1BXl2/663VOPwAAAAAAaP4I/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKEI/QAAAAAAGCq8Pov++Mc/6u23377qnN/85jd66KGH/LY7nU4tX75cGzZsUH5+vhwOh9LS0jR+/HjdeeedV33Mw4cPa9GiRdq9e7dKS0uVkJCgESNGKCMjQ/Hx8bWua0hNAAAAAABCVb1Cv0f79u3VvXv3gGMdO3b021ZVVaXHHntM2dnZCgsLU8+ePVVZWaldu3Zp165deuKJJ/TMM88EfLzNmzdr+vTpcjqdat++vXr16qXc3FytXLlSmZmZev/999W1a9dGrQkAAAAAQChrUOgfPny45syZc93z33jjDWVnZys5OVmLFy/WzTffLEn661//qmnTpmnx4sW69dZbNXLkSJ91RUVFeu655+R0OpWRkaGpU6cqPDxcZWVlevrpp/XZZ59p2rRp+vDDD2Wz2RqlJgAAAAAAoS5o5/SfO3dOq1evliTNnj3bG74ladSoUXr88cclKeBpA0uWLFFlZaUGDx6sp556SuHhlz+riImJ0R/+8AfFxMTo0KFD2rp1a6PVBAAAAAAg1AUt9GdlZcnpdColJUXDhg3zG3/wwQclSTk5OcrPz/cZ27RpkyRp7Nixfuvatm2r9PR0SdLGjRsbrSYAAAAAAKGuQaH/6NGjmjFjhh599FFNmTJFb731lr7++uuAc/fv3y9JGjhwYMDxxMREJScn+8yVpMLCQhUVFUmSBg8eHHDtoEGDJEkHDhxolJoAAAAAAJigQef0HzlyREeOHPH+OSsrS++8844effRR/epXv1JYWJh3LC8vT5LUrVu3Wh+vW7duOnXqlHJzc/3WORwOderUKeA6zwX8Tp48KafTKYfD0aCaAAAAAACYoF6hPyEhQf/n//wf/eM//qOSk5MVHR2t3NxcrVq1SqtXr9by5csVHh6u5557zrumpKRE0uXD8WvjGSstLfVuKy4u9o59/yJ9Hu3atZMkud1uXbx4UXFxcQ2qWR/h4UE7U6LewsLsPr8Hq16wNVVdhIZg9wHQ3NADAH0ASPRBS1Kv0D9u3Di/bb1799Yrr7yi5ORk/f73v9fy5cv1r//6r97D56uqqiTJ+y18IBEREZKkS5cuebfVZd2V8xtSs67sdpvi4trUe32wxca2aupduKFMf35oHLxO0NLRAwB9AEj0QUvQoMP7A5k4caJWrFihM2fOKCsrS48++qgkKTIyUpLkdDprXVtdXS1JioqK8m6ry7or5zekZl253ZZKSyvqvT5YwsLsio1tpdLSSrlc7qDVC7ZgPT+EpmD3AdDc0AMAfQBI9EGoi41tdd1HaTR66A8LC9Mtt9yiv/zlLzpx4sQVOxUr6e+H3AfiGfPMlf5++H1JSYksywp4iL/nFAC73a7o6OgG16yPmprQaRSXyx1S+1tXpj8/NA5eJ2jp6AGAPgAk+qAluCEncHgOp6+pqfFuS0lJkSSfDwK+z3PbPM/cK392Op0qLCwMuO7kyZOSpOTkZJ9D+etbEwAAAAAAE9yQ0O+5bd+VV9sfMGCAJGnv3r0B1xQVFenUqVM+cyUpKSlJCQkJkqQ9e/YEXOvZfuW6htQEAAAAAMAEjR76t23b5g39t912m3f7qFGj5HA4lJeXp507d/qtW716tSSpb9++6t69u8/YmDFjJElr1671W1dSUqLMzExJUnp6us9YQ2oCAAAAABDq6hz6v/76a7388ss6evSoz3a3261PP/1UM2bMkCSNGDFC/fv394536NDBe9X/mTNn6ptvvvGOZWVlacmSJZKkqVOn+tWcNGmSoqKitHv3bs2bN08ul0uSVFZWphkzZqisrEx9+/bVyJEjfdY1pCYAAAAAAKGuzhfyq6mp0Zo1a7RmzRq1a9dOSUlJCgsLU35+vveieIMGDdLvfvc7v7XPPvuscnJytG/fPt19993q1auXKioqvOfVT5w4UaNHj/Zb17lzZ/32t7/VjBkzNH/+fK1Zs0adOnVSbm6uKioq1KFDB7311lsBL/JX35oAAAAAAIS6Oof+Ll26aNq0adq/f7+OHz+uEydOqLq6Wm3bttXw4cN199136+6771ZYWJjf2qioKK1YsULLli3TJ598ory8PDkcDg0ZMkSPPPKI9zD+QNLT09W1a1ctXLhQe/bs0VdffaWEhATdf//9ysjIUPv27QOua0hNAAAAAABCmc2yLKupdyLUuVxunT9f3tS7cU3h4XbFxbXRhQvlQbkth6fetLnbdPx07bdNbCw9urTVW9N/HLTnh9AU7D4Amht6AKAPAIk+CHXx8W0UFnZ9Z+vfkKv3AwAAAACApkfoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUOGN8SDbt2/X5MmTJUldunRRVlZWwHnl5eVatGiRNm3apIKCArVu3Vq33HKLJk6cqKFDh161xs6dO7V06VIdOHBAFRUVSkpKUnp6uiZPnqzWrVvXuq4hNQEAAAAACGUN/qa/vLxcv/nNb6457/z58/rZz36md955R6dPn1aPHj0UGRmpbdu26ec//7nee++9WteuXLlSEyZM0LZt2xQZGakePXro9OnTWrBggR544AEVFxc3ek0AAAAAAEJdg0P/m2++qYKCAo0aNeqq82bOnKnc3Fz169dPW7Zs0bp167Rt2zbNmjVLlmVp9uzZOnLkiN+6Q4cO6bXXXpMkzZo1S9u2bdO6deu0ZcsW9evXT8ePH9dLL73UqDUBAAAAADBBg0L//v379d5772nUqFEaPXp0rfMOHz6srKws2e12vfnmm0pMTJQk2Ww2jRs3Tvfcc49cLpfmz5/vt3b+/Plyu9265557NG7cONlsNklSYmKi5s6dK7vdrs2bN+vo0aONVhMAAAAAABPUO/Q7nU699NJLioqK0ssvv3zVuZs2bZIkDRs2TN27d/cbHzdunKTL1waoqKjwbi8vL9dnn30mSRo7dqzfupSUFA0bNkySlJmZ2Sg1AQAAAAAwRb1D/8KFC/XVV1/pqaeeUqdOna46d//+/ZKkQYMGBRzv37+/IiIiVFVV5XO4/ZEjR1RdXa2IiAj1798/4NqBAwdKkg4cONAoNQEAAAAAMEW9Qv/x48e1cOFC9evXT+PHj7/m/Ly8PElSt27dAo47HA517txZkpSbm+vd7vk5KSlJDocj4FrPY165riE1AQAAAAAwRZ1v2WdZll588UXV1NTolVdeUVhY2DXXlJSUSJLatm1b6xzPWGlpab3WeeY2tGZ9hYc3+JqIN1xYmN3n92DVC7amqovQEOw+AJobegCgDwCJPmhJ6hz6V61apb1792r8+PH6wQ9+cF1rqqqqJKnWb+slKSIiQpJ06dKleq3zzG1ozfqw222Ki2vToMcIptjYVk29CzeU6c8PjYPXCVo6egCgDwCJPmgJ6hT6i4qKNHfuXCUmJmratGnXvS4yMlKVlZVyOp21zqmurpYkRUVF+ayTdF3rPHMbWrM+3G5LpaXN/2KAYWF2xca2UmlppVwud9DqBVuwnh9CU7D7AGhu6AGAPgAk+iDUxca2uu6jNOoU+l999VVdvHhRr7/+uqKjo+uwQ7GqrKz0OwT/Sp6x2NhY77baDt0PtO77h/HXt2Z91dSETqO4XO6Q2t+6Mv35oXHwOkFLRw8A9AEg0QctQZ1C/+HDhyVJr7zyil555RWfMc8h8oWFhbrtttskSX/84x916623KiUlRUVFRTpx4kTAx3U6nSooKJB0+TZ8Hp6fCwoK5HQ6Ax6qn5+f77fO8+f61AQAAAAAwBT1umrDuXPn/H5dvHhRkuR2u73bPIfWDxgwQJKUnZ0d8PEOHjwop9OpyMhI9enTx7u9T58+cjgcqq6u1sGDBwOu9Tymp4ZHfWsCAAAAAGCKOoX+rKws/e1vfwv46/XXX5ckdenSxbtt6NChkqQxY8ZIkr788suA37yvWbNGkjR8+HC1afP3C+JFR0fr9ttvlyStXbvWb11eXp527twpSUpPT/cZq29NAAAAAABMEZT7M/Tr108jRoyQy+XS008/rTNnzki6fPu/NWvWaP369bLb7ZoyZYrf2oyMDNlsNq1fv15r1qyRZVmSpDNnzmj69Olyu90aPXq00tLSGq0mAAAAAAAmqPMt++rrtdde00MPPaScnByNGjVKPXv21IULF1RYWCibzaZf//rX6tevn9+6/v376/nnn9ecOXP08ssva8GCBYqLi9OxY8dUXV2tm266Sa+++mqj1gQAAAAAwARBC/3x8fH66KOPtHjxYmVmZurYsWNq3bq1hg8frkmTJmnYsGG1rp0wYYJ69+6td999VwcPHtR3332npKQkpaena/LkybUent+QmgAAAAAAhDqb5TleHvXmcrl1/nx5U+/GNYWH2xUX10YXLpQH5bYcnnrT5m7T8dO13zqxsfTo0lZvTf9x0J4fQlOw+wBobugBgD4AJPog1MXHt1FY2PWdrR+Uc/oBAAAAAEDwEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADBUeH0Wbdy4UTt27FBOTo7OnDmj4uJiORwOpaSk6J/+6Z/085//XHFxcQHXlpeXa9GiRdq0aZMKCgrUunVr3XLLLZo4caKGDh161bo7d+7U0qVLdeDAAVVUVCgpKUnp6emaPHmyWrduXeu6htQEAAAAACBU1eub/nfeeUdr167V119/rYiICPXu3Vvt2rXT4cOHtWDBAv3kJz/R0aNH/dadP39eP/vZz/TOO+/o9OnT6tGjhyIjI7Vt2zb9/Oc/13vvvVdrzZUrV2rChAnatm2bIiMj1aNHD50+fVoLFizQAw88oOLi4oDrGlITAAAAAIBQVq/Q//DDD+s//uM/tHfvXmVlZemjjz7S1q1btWHDBqWmpuq7777TjBkz/NbNnDlTubm56tevn7Zs2aJ169Zp27ZtmjVrlizL0uzZs3XkyBG/dYcOHdJrr70mSZo1a5a2bdumdevWacuWLerXr5+OHz+ul156KeC+1rcmAAAAAAChrl6hf+zYsRo8eLAcDofP9t69e2v27NmSpGPHjun48ePescOHDysrK0t2u11vvvmmEhMTJUk2m03jxo3TPffcI5fLpfnz5/vVmz9/vtxut+655x6NGzdONptNkpSYmKi5c+fKbrdr8+bNfkcXNKQmAAAAAAChrtEv5HfzzTd7f66srPT+vGnTJknSsGHD1L17d79148aNkyRt375dFRUV3u3l5eX67LPPJF3+sOH7UlJSNGzYMElSZmamz1h9awIAAAAAYIJGD/3Z2dmSpNatW+umm27ybt+/f78kadCgQQHX9e/fXxEREaqqqvI53P7IkSOqrq5WRESE+vfvH3DtwIEDJUkHDhzw2V7fmgAAAAAAmKBRQr/b7VZRUZE+/vhjvfDCC5KkZ555Rm3atPHOycvLkyR169Yt4GM4HA517txZkpSbm+vd7vk5KSnJ73QCD89jXrmuITUBAAAAADBBvW7Z57Fs2TK9/vrrPtv69++vOXPmaPjw4T7bS0pKJElt27at9fE8Y6WlpfVa55nb0Jr1ER7e6AdNNLqwMLvP78GqF2xNVRehIdh9ADQ39ABAHwASfdCSNCj0JyYm6tZbb5XL5VJBQYHOnTunI0eOaP369RowYIBiY2O9c6uqqiSp1m/rJSkiIkKSdOnSpXqt88xtaM26stttiotrc+2JzURsbKum3oUbyvTnh8bB6wQtHT0A0AeARB+0BA0K/XfddZfuuusu75+PHj2qV199VZ9++qmOHz+ujz76SGFhYZKkyMhIVVZWyul01vp41dXVkqSoqCjvtsjISEm6rnWeuVeurU/NunK7LZWWNv8LAYaF2RUb20qlpZVyudxBqxdswXp+CE3B7gOguaEHAPoAkOiDUBcb2+q6j9JoUOj/vrS0NC1cuFCjR4/WkSNH9Oc//1k//elP//9OxaqystLvEPwrecauPEKgtkP3A637/mH89a1ZHzU1odMoLpc7pPa3rkx/fmgcvE7Q0tEDAH0ASPRBS9DoJ3BER0dryJAhkqScnBzv9pSUFEnSiRMnAq5zOp0qKCjwmXvlzwUFBbV+Y5+fn++3riE1AQAAAAAwwQ25akNNTY0kyeVyebcNGDBA0t9v6fd9Bw8elNPpVGRkpPr06ePd3qdPHzkcDlVXV+vgwYMB13oe01OjoTUBAAAAADBBo4f+4uJi7dq1S5J8gvSYMWMkSV9++WXAb97XrFkjSRo+fLjPrf6io6N1++23S5LWrl3rty4vL087d+6UJKWnp/uM1bcmAAAAAAAmqHPo37Vrl+bPn69Tp075jeXk5GjSpEkqKytTYmKiTwjv16+fRowYIZfLpaefflpnzpyRJFmWpTVr1mj9+vWy2+2aMmWK3+NmZGTIZrNp/fr1WrNmjSzLkiSdOXNG06dPl9vt1ujRo5WWluazriE1AQAAAAAIdTbLk6Cv05YtWzR16lRJUseOHZWQkKCwsDAVFhbq7Nmzki7fym/hwoV+h8yfP39eDz30kPLy8hQREaGePXvqwoULKiwslM1m08yZMzV+/PiAdZctW6Y5c+bIsix17txZcXFxOnbsmKqrq3XTTTdp1apVio+P91vXkJrXy+Vy6/z58gY9RjCEh9sVF9dGFy6UB+ViHZ560+Zu0/HTtV9MsbH06NJWb03/cdCeH0JTsPsAaG7oAYA+ACT6INTFx7e5cVfv/+EPf6gXXnhBX375pY4dO6a8vDxVV1crNjZWQ4cO1ciRI/XAAw8oOjo6wI7F66OPPtLixYuVmZmpY8eOqXXr1ho+fLgmTZqkYcOG1Vp3woQJ6t27t959910dPHhQ3333nZKSkpSenq7JkyfXenh+Q2oCAAAAABDK6vxNP/zxTf/V6/FNP5oTPtVGS0cPAPQBINEHoa4u3/TfkKv3AwAAAACApkfoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFDhTb0DCL6wsOB81hOsOgAAAACAwAj9LYjNZpPbbSk2tlVT7woAAAAAIAgI/S2I3W6T3W7T79/L1qmishte79a0BD36z31veB0AAAAAQGCE/hboVFGZjp8uueF1khOib3gNAAAAAEDtOOkaAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQ4XXdYFlWdq3b5+ysrKUnZ2tb775RhcvXlRMTIz69u2re++9V//yL/8im80WcH15ebkWLVqkTZs2qaCgQK1bt9Ytt9yiiRMnaujQoVetvXPnTi1dulQHDhxQRUWFkpKSlJ6ersmTJ6t169a1rmtITQAAAAAAQlWdv+nfuXOnHnroIS1evFh79+5VTEyMevfuLcuy9Pnnn+vZZ5/VL3/5S1VXV/utPX/+vH72s5/pnXfe0enTp9WjRw9FRkZq27Zt+vnPf6733nuv1rorV67UhAkTtG3bNkVGRqpHjx46ffq0FixYoAceeEDFxcUB1zWkJgAAAAAAoazOod+yLCUnJ2vmzJnasWOHtmzZoo8//lhffvmlfvvb3yoiIkLbtm3TvHnz/NbOnDlTubm56tevn7Zs2aJ169Zp27ZtmjVrlizL0uzZs3XkyBG/dYcOHdJrr70mSZo1a5a2bdumdevWacuWLerXr5+OHz+ul156KeD+1rcmAAAAAAChrs6hv3///srMzNSjjz6q9u3b+4zde++9mjp1qiTpww8/lNvt9o4dPnxYWVlZstvtevPNN5WYmChJstlsGjdunO655x65XC7Nnz/fr+b8+fPldrt1zz33aNy4cd5TBxITEzV37lzZ7XZt3rxZR48e9VnXkJoAAAAAAIS6Oof+6OhoORyOWseHDx8uSSouLtb58+e92zdt2iRJGjZsmLp37+63bty4cZKk7du3q6Kiwru9vLxcn332mSRp7NixfutSUlI0bNgwSVJmZqbPWH1rAgAAAABggka/ev+lS5e8P0dFRXl/3r9/vyRp0KBBAdf1799fERERqqqq8jnc/siRI6qurlZERIT69+8fcO3AgQMlSQcOHPDZXt+aAAAAAACYoM5X77+WP//5z5KktLQ0RUdHe7fn5eVJkrp16xZwncPhUOfOnXXixAnl5uZ6g3xubq4kKSkpqdYjDDyP6Znb0Jr1ER7e/O9+aLcHvqOCacLCmv/fBZqO5/XB6wQtFT0A0AeARB+0JI0a+g8dOqTVq1dLkiZPnuwzVlJSIklq27Ztres9Y6WlpfVa55nb0Jp1ZbfbFBfXpt7r0bhiY1s19S4gBPA6QUtHDwD0ASDRBy1Bo4X+c+fO6cknn1RNTY3uuOMO/eQnP/EZr6qqkqSrXg8gIiJCku8pAnVZ55nb0Jp15XZbKi1t/tcEcDjCFB0dde2JIa60tFIul/vaE9EihYXZFRvbitcJWix6AKAPAIk+CHWxsa2u+yiNRgn9ZWVleuKJJ1RQUKB+/fppzpw5fnMiIyNVWVkpp9NZ6+NUV1dL8r0WQGRkpCRd1zrP3IbWrI+amubfKC3l0B2Xyx0Sfx9oWrxO0NLRAwB9AEj0QUvQ4BRYXl6uxx9/XIcPH1avXr307//+7z7n8nvExsZK8j8E/0qeMc9cqfZD9wOt+/5h/PWtCQAAAACACRoU+isrK/WLX/xC+/fvV0pKipYuXaq4uLiAc1NSUiRJJ06cCDjudDpVUFDgM/fKnwsKCmr9xj4/P99vXUNqAgAAAABggnqH/qqqKk2ZMkW7d+9Wly5dtGzZMnXs2LHW+QMGDJAkZWdnBxw/ePCgnE6nIiMj1adPH+/2Pn36yOFwqLq6WgcPHgy41vOYnhoNrQkAAAAAgAnqFfqdTqeefPJJffHFF0pMTNTy5cvVuXPnq64ZM2aMJOnLL78M+M37mjVrJEnDhw9XmzZ/vxJ+dHS0br/9dknS2rVr/dbl5eVp586dkqT09PRGqQkAAAAAgAnqHPpdLpdmzJih7du3q2PHjlq+fLm6du16zXX9+vXTiBEj5HK59PTTT+vMmTOSJMuytGbNGq1fv152u11TpkzxW5uRkSGbzab169drzZo1sixLknTmzBlNnz5dbrdbo0ePVlpaWqPVBAAAAAAg1NX56v0bN27Upk2bJF2+3d2vf/3rWue+9NJL6tu3r/fPr732mh566CHl5ORo1KhR6tmzpy5cuKDCwkLZbDb9+te/Vr9+/fwep3///nr++ec1Z84cvfzyy1qwYIHi4uJ07NgxVVdX66abbtKrr74acB/qWxMAAAAAgFBX59DvucWdJJ0+fVqnT5+udW5ZWZnPn+Pj4/XRRx9p8eLFyszM1LFjx9S6dWsNHz5ckyZN0rBhw2p9rAkTJqh379569913dfDgQX333XdKSkpSenq6Jk+eXOvh+Q2pCQAAAABAKLNZnmPlUW8ul1vnz5c39W5cU2RkuGJjW2na3G06frr22xg2ln/6YRc988igoNXr0aWt3pr+Y124UM69RlGr8HC74uLa8DpBi0UPAPQBINEHoS4+vo3Cwq7vbP0G3bIPAAAAAAA0X4R+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMRegHAAAAAMBQhH4AAAAAAAxF6AcAAAAAwFCEfgAAAAAADEXoBwAAAADAUIR+AAAAAAAMFV6fRWfPntXnn3+uQ4cO6X/+53905MgRVVVVaciQIVq5cuVV1zqdTi1fvlwbNmxQfn6+HA6H0tLSNH78eN15551XXXv48GEtWrRIu3fvVmlpqRISEjRixAhlZGQoPj7+htQEAAAAACBU1Sv0//nPf9brr79e53VVVVV67LHHlJ2drbCwMPXs2VOVlZXatWuXdu3apSeeeELPPPNMwLWbN2/W9OnT5XQ61b59e/Xq1Uu5ublauXKlMjMz9f7776tr166NWhMAAAAAgFBWr8P7o6Oj9Q//8A/6xS9+obffflsZGRnXte6NN95Qdna2kpOT9emnn2rDhg36y1/+ovnz5ysiIkKLFy9WVlaW37qioiI999xzcjqdysjI0H/913/p448/1n/913/pH//xH3X27FlNmzZNlmU1Wk0AAAAAAEJdvUL/Aw88oKVLl2r69Om644471L59+2uuOXfunFavXi1Jmj17tm6++Wbv2KhRo/T4449Lkt5++22/tUuWLFFlZaUGDx6sp556SuHhlw9QiImJ0R/+8AfFxMTo0KFD2rp1a6PVBAAAAAAg1AXtQn5ZWVlyOp1KSUnRsGHD/MYffPBBSVJOTo7y8/N9xjZt2iRJGjt2rN+6tm3bKj09XZK0cePGRqsJAAAAAECoC1ro379/vyRp4MCBAccTExOVnJzsM1eSCgsLVVRUJEkaPHhwwLWDBg2SJB04cKBRagIAAAAAYIKghf68vDxJUrdu3Wqd4xnLzc31W+dwONSpU6eA6zwX8Dt58qScTmeDawIAAAAAYIJ6Xb2/PkpKSiRdPhy/Np6x0tJS77bi4mLvmM1mC7iuXbt2kiS3262LFy8qLi6uQTXrIzw8aJ+f1JvdHvi/n2nCwpr/3wWajuf1wesELRU9ANAHgEQftCRBC/1VVVWSLn9jX5uIiAhJ0qVLl+q17sr5DalZV3a7TXFxbeq9Ho0rNrZVU+8CQgCvE7R09ABAHwASfdASBC30R0ZGSpLP4fffV11dLUmKioqq17or5zekZl253ZZKSyvqvT5YHI4wRUfX/3mGiosXL8nt9r99443gdlsBbxWJ5isszK7Y2FYqLa2Uy+Vu6t0Bgo4eAOgDQKIPQl1sbKvrPkojaKE/NjZW0t8PuQ/EM+aZK/398PuSkhJZlhXwEH/PKQB2u13R0dENrlkfNTXNv1FMP3SnXUyk3G4rqB9suFxuFRdXBO1DBjQel8sdEn0L3Cj0AEAfABJ90BIELfSnpKRo7969OnHiRK1zPLfNS0lJ8VknXf62vrCwUElJSX7rTp48KUlKTk72OZS/vjURmqJbOWS32/T797J1qqjshtdLTozRMw8PlN1uI/QDAAAAaJaCFvoHDBigjz/+WHv37g04XlRUpFOnTnnneiQlJSkhIUFnzpzRnj179NOf/tRv7Z49e/zWNaQmQtupojIdP1370R0AAAAA0FIE7XjvUaNGyeFwKC8vTzt37vQbX716tSSpb9++6t69u8/YmDFjJElr1671W1dSUqLMzExJUnp6eqPVBAAAAAAg1AUt9Hfo0EHjxo2TJM2cOVPffPONdywrK0tLliyRJE2dOtVv7aRJkxQVFaXdu3dr3rx5crlckqSysjLNmDFDZWVl6tu3r0aOHNloNQEAAAAACHX1Ory/sLBQ9957r/fPnivg7927V0OHDvVuf/zxx/XEE094//zss88qJydH+/bt0913361evXqpoqLCe179xIkTNXr0aL96nTt31m9/+1vNmDFD8+fP15o1a9SpUyfl5uaqoqJCHTp00FtvvRXwIn/1rQlcr2BeINHttrh+AAAAAIDrVq/Q73K5vFfMv1JNTY3P9kuXLvmMR0VFacWKFVq2bJk++eQT5eXlyeFwaMiQIXrkkUe8h/EHkp6erq5du2rhwoXas2ePvvrqKyUkJOj+++9XRkaG2rdvH3BdQ2oCV+O5W0Aw723K3QIAAAAA1EW9Qn9ycrL+9re/1atgRESEJk+erMmTJ9d5bb9+/fRv//ZvQa0J1Ia7BQAAAABo7oJ29X7AVNwtAAAAAEBzFbyTkQEAAAAAQFAR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADAUoR8AAAAAAEMR+gEAAAAAMBShHwAAAAAAQxH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADBUeFPvAIC6CQsL7md1brclt9sKak0AAAAAjYPQD4SIdjGRcrstxca2Cmpdl8ut4uIKgj8AAAAQggj9QIiIbuWQ3W7T79/L1qmisqDUTE6M0TMPD5TdbiP0AwAAACGI0A+EmFNFZTp+uqSpdwMAAABACOBCfgAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKG4ZR+AawoLC97ng263JbfbClo9AAAAwGSEfgC1ahcTKbfbUmxsq6DVdLncKi6uIPgDAAAAjYDQD6BW0a0csttt+v172TpVVHbD6yUnxuiZhwfKbrcR+gEAAIBGQOgHcE2nisp0/HRJU+8GAAAAgDriQn4AAAAAABiK0A8AAAAAgKEI/QAAAAAAGIrQDwAAAACAoQj9AAAAAAAYitAPAAAAAIChCP0AAAAAABiK0A8AAAAAgKHCm3oHAOD7wsJu3OeRnsf2/O52W3K7rRtWDwAAAGhKhH4AzUa7mEi53ZZiY1vd8FqeGi6XW8XFFQR/AAAAGInQD6DZiG7lkN1u0+/fy9aporIbXi85MUbPPDxQdruN0A8AAAAjEfoBNDunisp0/HRJU+8GAAAAEPK4kB8AAAAAAIbim34ALd6NvHBgU+NChQAAAC0boR9AixXMCwd6uNyWwuy24NXjQoUAAAAtGqEfQIsV7AsH3pqWoEf/uS8XKgQAAEDQEPoBtHjBunBgckJ0UOsBAAAALSb079y5U0uXLtWBAwdUUVGhpKQkpaena/LkyWrdunVT7x4AAAAAAI2uRYT+lStXavbs2bIsS506dVLnzp117NgxLViwQJs3b9aqVavUrl27pt5NALghgnmhQi4cCAAA0LwYH/oPHTqk1157TZI0a9YsjR07VjabTUVFRZoyZYpycnL00ksv6Y9//GMT7ykANK4muVAhFw4EAABoVowP/fPnz5fb7da9996rcePGebcnJiZq7ty5uuuuu7R582YdPXpUaWlpTbinANC4gn2hQs+FAx2OMLlc7htez4OjCwAAAGpndOgvLy/XZ599JkkaO3as33hKSoqGDRumHTt2KDMzk9APwEjBunBgUxxZIF0+uqCs7JIsKzjBnw8ZAABAKDE69B85ckTV1dWKiIhQ//79A84ZOHCgduzYoQMHDgR57wDALME+skCS+twUryfu+YHatQveBVn5kAEAAIQSo0N/bm6uJCkpKUkOhyPgnG7duvnMBQA0TDBvSZicEB3UDxpM+JDBc2HH2i7w2BI+ZLDbbbLbbUGr1xL+mwZTY/z9XasPrsTfH4BQZ7OC9VVFE1iyZIneeOMN3XLLLVq7dm3AOdu3b/fetm/fvn31qmNZofFmYLNJdrtdxWVVqgnC+baREWGKaR1BvRCt1xQ1qUe95l7TU+9iRbVcQfj/fniYXa2jwmWzBS+gWpYVtKMYmorNZuO/aQjj7w9oPHa7XW538K7DEypCoeXt9uv/f6HR3/RXVVVJUq3f8ktSRESEz9z6sNlsCgsL3ptPQ7WLiaQe9Zp1TepRr7nXjG4dEdR6wRTsQNUS8N80tPH3B9PZ7cG7tS+ahtF/w5GRl/8R6HQ6a51TXV3tMxcAAAAAAFMYHfrbtm0rSSopqf3cUs+YZy4AAAAAAKYwOvSnpKRIkgoKCmr9tj8/P99nLgAAAAAApjA69Pfp00cOh0PV1dU6ePBgwDnZ2dmSpAEDBgRxzwAAAAAAuPGMDv3R0dG6/fbbJSng1fvz8vK0c+dOSVJ6enpQ9w0AAAAAgBvN6NAvSRkZGbLZbFq/fr3WrFnjveXKmTNnNH36dLndbo0ePVppaWlNvKcAAAAAADQum9UCbjy6bNkyzZkzR5ZlqXPnzoqLi9OxY8dUXV2tm266SatWrVJ8fHxT7yYAAAAAAI2qRYR+Sfriiy/07rvv6uDBg6qoqFBSUpLS09M1efJktWnTpql3DwAAAACARtdiQj8AAAAAAC2N8ef0AwAAAADQUhH6AQAAAAAwFKEfAAAAAABDEfoBAAAAADBUeFPvAG68nTt3aunSpTpw4IDfnQtat27d1LsHXJVlWdq3b5+ysrKUnZ2tb775RhcvXlRMTIz69u2re++9V//yL/8im80WcH15ebkWLVqkTZs2qaCgQK1bt9Ytt9yiiRMnaujQoVetTe+gudu+fbsmT54sSerSpYuysrICzqMPYKLt27frgw8+0P79+1VcXKy2bduqa9euGjp0qJ588kmFh/v+M9fpdGr58uXasGGD8vPz5XA4lJaWpvHjx+vOO++8aq3Dhw9r0aJF2r17t0pLS5WQkKARI0YoIyOD2z6jSVy4cEFLly7V1q1bderUKTmdTsXHx+uHP/yhxo8fr0GDBgVcx/tBy8TV+w23cuVKzZ49W5ZlqVOnToqPj9exY8dUXV2tHj16aNWqVWrXrl1T7yZQqy+++EITJkzw/rlr166KjY3V6dOnVVxcLEn68Y9/rD/+8Y+KiIjwWXv+/Hn967/+q3JzcxUREaGePXvq/Pnz+vbbb2Wz2fTSSy/p4YcfDliX3kFzV15errvvvlsFBQWSag/99AFMU1NToxdeeEEbNmyQJHXu3FkdOnRQcXGxvv32WzmdTu3du9fnlsxVVVV67LHHlJ2drbCwMPXs2VOVlZXKz8+XJD3xxBN65plnAtbbvHmzpk+fLqfTqfbt26tTp07Kzc1VRUWFOnbsqPfff19du3a98U8c+P/y8vL0yCOP6OzZs7Lb7erSpYuio6OVn5+v8vJy2Ww2Pf/88z7/fpJ4P2jRLBjrf/7nf6y0tDSrd+/e1urVqy23221ZlmV9++231n333WelpqZa//t//+8m3kvg6j7//HNr5MiR1vLly61z5875jK1bt876X//rf1mpqanW7373O7+1v/zlL63U1FTrvvvus7799lvLsizL7XZbq1evtlJTU60+ffpYhw8f9ltH7yAUvPrqq1Zqaqo1ZcoUKzU11RoxYkTAefQBTDNz5kwrNTXV+tnPfmbl5OT4jFVUVFhbtmyxqqurfbZ7+mXkyJHW8ePHvdu3bNnifR/561//6lfr22+/tW655RYrNTXVeuuttyyn02lZlmWVlpZakyZNslJTU63777/f2x9AMDz66KNWamqqdeedd1pff/21d/ulS5esOXPmWKmpqVbfvn2t3Nxcn3W8H7RchH6Def4h+Nxzz/mN5ebmWmlpaVZqaqp15MiRJtg74PqUlZX5/ePtSgsWLLBSU1OtIUOGWC6Xy7s9JyfHSk1NtdLS0qy8vDy/dc8++2ytb1L0Dpq7ffv2WWlpadaUKVOsjz76qNbQTx/ANF988YX39V5WVnZda86ePWv169fPSk1Ntb744gu/8bfeessbhL7v//7f/2ulpqZaDz/8sN9YcXGxNXDgwFo/MABuhLKyMqt3795Wamqq9Ze//MVv3O12W3fccYeVmppqrVy50rud94OWjQv5Gaq8vFyfffaZJGns2LF+4ykpKRo2bJgkKTMzM6j7BtRFdHS0HA5HrePDhw+XJBUXF+v8+fPe7Zs2bZIkDRs2TN27d/dbN27cOEmXzwmtqKjwbqd30Nw5nU699NJLioqK0ssvv3zVufQBTLN06VJJ0sSJExUdHX1da7KysuR0On1et1d68MEHJUk5OTnew/09PD0UqA/atm2r9PR0SdLGjRuv/0kADVBdXS3r/5+d3a1bN79xm83mPd2kpqbGu533g5aN0G+oI0eOqLq6WhEREerfv3/AOQMHDpQkHThwIJi7BjSqS5cueX+Oiory/rx//35JqvVCNv3791dERISqqqp05MgR73Z6B83dwoUL9dVXX+mpp55Sp06drjqXPoBJqqqq9Pnnn0uSfvSjH+nYsWOaPXu2Jk6cqF/+8peaN2+eTp8+7bfO0wee1+z3JSYmKjk52WeuJBUWFqqoqEiSNHjw4IBrPb1FHyBY4uPjvf/v37dvn994RUWFjh49Kkn6wQ9+4N3O+0HLRug3VG5uriQpKSmp1m9JPZ8OeuYCoejPf/6zJCktLc3nW5+8vDxJgT8FlySHw6HOnTtL8u0BegfN2fHjx7Vw4UL169dP48ePv+Z8+gAmOXr0qJxOpyQpOztb9957r1asWKHPP/9cW7du1fz585Wenq5PP/3UZ921+uDKsStfz551Doej1g/YPN+onjx50rtvwI02Y8YM2Ww2/e53v9MHH3ygs2fPqrKyUgcPHtSUKVN07tw5/fSnP/X5oIv3g5aNW/YZqqSkRNLlQ89q4xnzzAVCzaFDh7R69WpJ8t62zKMuPVBaWlqvdfQOgsmyLL344ouqqanRK6+8orCwsGuuoQ9gkrNnz3p/njVrlvr27asXX3xRaWlpKiws1JtvvqmNGzfq+eef180336y+fftKqn8feO4Q07Zt21pvC+u5Wrnb7dbFixcVFxdX7+cHXK+f/vSniomJ0YIFC/Tiiy/6jHXs2FG/+c1vvKetePB+0LLxTb+hqqqqJOmq50J7bm/mmQuEknPnzunJJ59UTU2N7rjjDv3kJz/xGa9LD1x5igC9g+Zq1apV2rt3rx5++GGfQzavhj6AScrLy70/R0VFafHixd5Dkrt37665c+eqT58+cjqdeuedd7xzg9EHV84HguHEiRP67rvvvLfs6927t1q1aqWzZ89q3bp1+vrrr33m837QshH6DRUZGSlJVz3UrLq62mcuECrKysr0xBNPqKCgQP369dOcOXP85tSlB668FgC9g+aoqKhIc+fOVWJioqZNm3bd6+gDmOTK19p9993n982j3W733pf8v//7v+V2u33W3cg++P7+ATfSK6+8otdff11xcXH6z//8T2VlZWnDhg3auXOnJk2apAMHDuihhx7yucYF7wctG6HfUNdzmM31HK4DNDfl5eV6/PHHdfjwYfXq1Uv//u//HvAKzrGxsZKurwc8cyV6B83Tq6++qosXL+rFF1+87iuWS/QBzHLla61Hjx4B59x8882SLr9XeA7Pb4w+8Fwt/fs8Nex2e516E6ivo0eP6v3335fD4dC8efN00003eceioqL03HPP6Uc/+pEuXryohQsXesd4P2jZCP2GSklJkSQVFBTU+smc57Y0nrlAc1dZWalf/OIX2r9/v1JSUrR06dJaz5/0vK5PnDgRcNzpdKqgoMBn7pU/0ztoTg4fPizp8rc7t912m8+v2bNnS7p8pXHPtr1790qiD2AWT6CXaj/U+MpvGj3f9F+rD6TAr2fPz06nU4WFhQHXnTx5UpKUnJx81cOfgcaSnZ0ty7LUvXt3denSJeCc2267TdLlax958H7QshH6DdWnTx85HA5VV1fr4MGDAedkZ2dLkgYMGBDEPQPqp6qqSlOmTNHu3bvVpUsXLVu2TB07dqx1vud17Xmdf9/BgwfldDoVGRmpPn36eLfTO2jOzp075/fr4sWLki4HHM82zz/M6AOYJDEx0RtyPGH7+zzbIyMjvRfZ87xGPR+GfV9RUZFOnTrlM1e6fLXyhIQESdKePXsCrvVspw8QLFde2+Jarjz9hPeDlo3Qb6jo6GjdfvvtkqS1a9f6jefl5Wnnzp2SpPT09KDuG1BXTqdTTz75pL744gslJiZq+fLl3tvK1GbMmDGSpC+//DLgp9pr1qyRJA0fPlxt2rTxbqd30BxlZWXpb3/7W8Bfr7/+uiSpS5cu3m1Dhw6VRB/APHfddZck6ZNPPlFNTY3f+IcffihJGjx4sMLDL9+katSoUXI4HD6v2yt57gLTt29fde/e3WfM00OB+qCkpESZmZmS6AMEj+dw/hMnTvics3+lzz//3GeuxPtBS0foN1hGRoZsNpvWr1+vNWvWeM9HO3PmjKZPny63263Ro0crLS2tifcUqJ3L5dKMGTO0fft2dezYUcuXL/feF/lq+vXrpxEjRsjlcunpp5/WmTNnJF2+7dmaNWu0fv162e12TZkyxW8tvQNT0AcwzaRJkxQTE6NTp05p1qxZ3quFW5alFStWaOvWrbLZbD63ce3QoYPGjRsnSZo5c6a++eYb71hWVpaWLFkiSZo6dWrAelFRUdq9e7fmzZsnl8sl6fIFZWfMmKGysjL17dtXI0eOvGHPGbjSbbfdpvbt28vpdOqpp55Sbm6ud+zSpUv63e9+py+++EKSdM8993jHeD9o2WxWbVcmgRGWLVumOXPmyLIsde7cWXFxcTp27Jiqq6t10003adWqVYqPj2/q3QRq9emnn2rGjBmSLn+TmZiYWOvcl156yXtfZkk6f/68HnroIeXl5SkiIkI9e/bUhQsXVFhYKJvNppkzZ2r8+PEBH4veQaj4+OOP9cILL6hLly7KysryG6cPYJodO3ZoypQpunTpkmJiYpSSkqJvv/1WZ8+elc1m07PPPqtJkyb5rLl06ZImTJigffv2KSwsTL169VJFRYX3XOSJEyfqV7/6VcB6mZmZmjFjhmpqatS+fXt16tRJubm5qqioUIcOHbRq1Sq/IwSAG2nHjh2aOnWqKioqZLfblZSUpDZt2ig/P1+VlZWSpIcfflgvv/yyzzreD1ouQn8L8MUXX+jdd9/VwYMHVVFRoaSkJKWnp2vy5Mk+h+8AzZEn0FyPFStWeA9r9rh48aIWL16szMxMFRQUqHXr1urfv78mTZqkYcOGXfXx6B2EgmuFfok+gHny8vK0cOFC7dixQ999952io6P1wx/+UI899piGDBkScE11dbWWLVumTz75RPn5+XI4HOrTp48eeeQR76HPtcnJydHChQu1Z88elZaWKiEhQSNGjFBGRobat29/I54icFUnT57UsmXLtGPHDhUUFMjlcqldu3bq37+/xo4dqx//+McB1/F+0DIR+gEAAAAAMBTn9AMAAAAAYChCPwAAAAAAhiL0AwAAAABgKEI/AAAAAACGIvQDAAAAAGAoQj8AAAAAAIYi9AMAAAAAYChCPwAAAAAAhiL0AwAAAABgKEI/AAAAAACGIvQDAAAAAGAoQj8AAAAAAIYi9AMAAAAAYChCPwAAAAAAhvp/QP34uiazhdEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XlG2yAGgjCi"
      },
      "source": [
        "From the above graph, we can see that most of the description lengths are less than 100 words. **Hence, the MAX_LEN has been chosen to be 128**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKTv9T-jg4dG"
      },
      "source": [
        "## **Data Formatting and Training of the BERT Model**\n",
        "\n",
        "In the following code snippets, the training data has been first prepared according to BERT's requirements and then split into training and validation sets. The model is then trained and validated and finally tested on the testing dataframe that was made earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRMsSXuKYZ99"
      },
      "source": [
        "### 1. Mapping the sentences to their Word IDs\n",
        "\n",
        "In the following code snippet, with the help of **tokenizer.encode()** function splits the sentences into tokens and adds the special tokens to the start and end of the tokens and finally maps them to their corresponding word IDS."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization of all the sentences followed by the mapping of the tokens to their word ids\n",
        "tokenized_inputs = []\n",
        "tokenized_len = []\n",
        "input_data = balanced_df[\"cleaned_desc\"].tolist()\n",
        "\n",
        "for sentence in input_data:\n",
        "  '''\n",
        "    tokenizer.encode does the following:\n",
        "    1. tokenizes the sentences\n",
        "    2. adds [CLS] to the start of the tokens and [SEP] to the end of the tokens\n",
        "    3. Maps the tokens to their word IDS\n",
        "  '''\n",
        "  # Handle potential NaN values and other non-string types\n",
        "  if isinstance(sentence, str):\n",
        "    encoded_sentence = tokenizer.encode(sentence, add_special_tokens=True)\n",
        "    tokenized_inputs.append(encoded_sentence)\n",
        "    tokenized_len.append(len(encoded_sentence))\n",
        "  else:\n",
        "    # Handle NaN or non-string values by appending an empty list (or another suitable default)\n",
        "    tokenized_inputs.append([])  # Replace [] with a suitable default if needed\n",
        "    tokenized_len.append(0)\n",
        "    print(f\"Skipping non-string value: {sentence}\")\n",
        "\n",
        "balanced_df[\"Token_ids\"] = tokenized_inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNCdR1hzvMaU",
        "outputId": "f17ebf7e-ae1c-483b-e757-6fa562a22fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping non-string value: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeIrIsockfkE"
      },
      "source": [
        "The following Seaborn plot helps us in visualising the distribution of token lengths across the entire corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "tx7Lk2moMt_p",
        "outputId": "bf8b0df2-5b84-4ad7-c352-3db4f4069d5c"
      },
      "source": [
        "sns.distplot(tokenized_len)\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaB-OGnhYepB"
      },
      "source": [
        "### 2. Padding and Truncating the Word IDs and creating Attention Masks\n",
        "\n",
        "As the tokenizer.encode() function does not handle padding, it is handled separately using pad_sequence and thus, the tokens are then truncated to a MAX_LEN of 128 that was chosen above. Finally, to separate the paddings from the tokens attention masks are created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk07sMHxYhCu"
      },
      "source": [
        "# from the above, we can see that most of the sentences are below 200 -> choosing a max_len of 128\n",
        "max_len = 128\n",
        "#padding and truncating the sentences according to the maximum length\n",
        "tokenized_inputs = pad_sequences(balanced_df[\"Token_ids\"], maxlen=max_len, dtype=\"long\",value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "#creating the attention masks\n",
        "attention_mask = []\n",
        "\n",
        "for sentence in tokenized_inputs:\n",
        "  temp_mask = [int(token_id>0) for token_id in sentence]\n",
        "  attention_mask.append(temp_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJAIR4DsaXzq"
      },
      "source": [
        "### 3. Splitting the dataset into training and validation set\n",
        "\n",
        "The input descriptions, labels and attention masks are then converted into PyTorch tensors. Then these are split into training and validation sets for training the model and testing it. Then for the training and validation sets, dataloaders are created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFj2_EW_aJ9u",
        "outputId": "fb6e7bf8-d138-47c4-fcf9-db850c626907"
      },
      "source": [
        "description_inputs = torch.tensor(tokenized_inputs)\n",
        "category_labels = torch.tensor(balanced_df[\"categories\"].values)\n",
        "mask = torch.tensor(attention_mask)\n",
        "\n",
        "print(description_inputs.shape, category_labels.shape, mask.shape)\n",
        "\n",
        "#splitting the dataset and attention masks\n",
        "training_dataset, validation_dataset, training_categories, validation_categories = train_test_split(description_inputs,\n",
        "                                                                                                    category_labels,\n",
        "                                                                                                    random_state = 42,\n",
        "                                                                                                    test_size = 0.15,\n",
        "                                                                                                    shuffle=True)\n",
        "\n",
        "training_mask, validation_mask, _, _ = train_test_split(mask,\n",
        "                                                        category_labels,\n",
        "                                                        random_state = 42,\n",
        "                                                        test_size = 0.15,\n",
        "                                                        shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([13499, 128]) torch.Size([13499]) torch.Size([13499, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBPS2e9KbC_r"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#barch size has been chosen to be 16 as a batch size of 32 gave out of memory errors (limitation)\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# creating the dataloader for the training dataset\n",
        "training_data = TensorDataset(training_dataset, training_mask, training_categories)\n",
        "training_dataloader = DataLoader(training_data, sampler=RandomSampler(training_data), batch_size=BATCH_SIZE)\n",
        "\n",
        "# creating the dataloader for the validation dataset\n",
        "validation_data = TensorDataset(validation_dataset, validation_mask, validation_categories)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=SequentialSampler(validation_data), batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LywHNrdiftUb"
      },
      "source": [
        "### 4. Training the Multiclass Classification Model\n",
        "\n",
        "For training our model we have modified the pre-trained BERT model to perform Multiclass Classification. We are using BertForSequenceClassification model and the \"bert-base-uncased\" model variant for the same. AdamW Optimizer has been used and the following hyperparameters are used for fine-tuning:\n",
        "\n",
        "1. Number of epochs: 4\n",
        "2. Learning Rate: 3e-5\n",
        "3. BATCH_SIZE was chosen to be 32 while creating the DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# choosing the model version that has only lowercase characters and is the smaller one out the two versions\n",
        "option_name = \"bert-base-uncased\"\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(option_name,\n",
        "                                                      num_labels = 13,\n",
        "                                                      output_attentions = False,\n",
        "                                                      output_hidden_states = False)\n",
        "model.cuda()\n",
        "\n",
        "#optimzer: object that actually performs updates to our weights\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 3e-5,\n",
        "                  eps = 1e-8)\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "BNQE2WyX8Qhw",
        "outputId": "78d69ccc-6967-4aa8-aff2-34bf98ff2fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-237-b210e23eafa5>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                       \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                       output_hidden_states = False)\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#optimzer: object that actually performs updates to our weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2764\u001b[0m             )\n\u001b[1;32m   2765\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2766\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2768\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \"\"\"\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m         \"\"\"\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk5slTXxgXtJ"
      },
      "source": [
        "#HELPER FUNCTIONS\n",
        "\n",
        "# this function takes time in seconds and returns a string hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "# this function calculates the accuracy by taking in the predicted and actual labels as parameters\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "import random\n",
        "import numpy as np\n",
        "import timeit\n",
        "import datetime\n",
        "\n",
        "# Assuming you have defined training_dataset, training_mask, training_categories,\n",
        "# validation_dataset, validation_mask, and validation_categories in previous cells\n",
        "\n",
        "# Batch size\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Creating dataloaders\n",
        "training_data = TensorDataset(training_dataset, training_mask, training_categories)\n",
        "training_dataloader = DataLoader(training_data, sampler=RandomSampler(training_data), batch_size=BATCH_SIZE)\n",
        "\n",
        "validation_data = TensorDataset(validation_dataset, validation_mask, validation_categories)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=SequentialSampler(validation_data), batch_size=BATCH_SIZE)\n",
        "\n",
        "# Model and optimizer\n",
        "option_name = \"bert-base-uncased\"\n",
        "model = BertForSequenceClassification.from_pretrained(option_name,\n",
        "                                                      num_labels=13,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "model.cuda()\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=3e-5,\n",
        "                  eps=1e-8)\n",
        "\n",
        "# Number of training epochs\n",
        "epochs = 4\n",
        "\n",
        "# Helper functions\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, optimizer, train_loader, valid_loader, num_epochs, eval_every):\n",
        "    seed_val = 42\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    running_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    for each_epoch in range(num_epochs):\n",
        "        print('\\n')\n",
        "        print(\"*************** Epoch {:}/{:} ***************\".format(each_epoch+1, num_epochs))\n",
        "        print(\"Training....\")\n",
        "\n",
        "        start = timeit.default_timer()\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        for step, (input_desc_ids, input_mask, input_label) in enumerate(train_loader):\n",
        "            if step % eval_every == 0 and step != 0:\n",
        "                stop = timeit.default_timer()\n",
        "                time_elapsed = format_time(stop - start)\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), time_elapsed))\n",
        "\n",
        "            input_desc_ids = input_desc_ids.to(device)\n",
        "            input_mask = input_mask.to(device)\n",
        "            input_label = input_label.to(device)\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs = model(input_desc_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=input_mask,\n",
        "                            labels=input_label)\n",
        "\n",
        "            loss = outputs.loss\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        average_train_loss = running_loss / len(train_loader)\n",
        "        train_loss_list.append(average_train_loss)\n",
        "\n",
        "        print('\\n')\n",
        "        print(\"  Average training loss: {0:.2f}\".format(average_train_loss))\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"Validating....\")\n",
        "\n",
        "        start = timeit.default_timer()\n",
        "        model.eval()\n",
        "\n",
        "        valid_accuracy = 0.0\n",
        "        steps_eval = 0\n",
        "\n",
        "        for (input_ids, input_masks, input_labels) in valid_loader:\n",
        "            input_ids = input_ids.to(device)\n",
        "            input_masks = input_masks.to(device)\n",
        "            input_labels = input_labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids,\n",
        "                                token_type_ids=None,\n",
        "                                attention_mask=input_masks)\n",
        "\n",
        "            logits = outputs.logits.detach().cpu().numpy()\n",
        "            label_ids = input_labels.to('cpu').numpy()\n",
        "\n",
        "            temp_accuracy = flat_accuracy(logits, label_ids)\n",
        "            valid_accuracy += temp_accuracy\n",
        "            steps_eval += 1\n",
        "\n",
        "        average_valid_accuracy = valid_accuracy / steps_eval\n",
        "        valid_loss_list.append(average_valid_accuracy)\n",
        "\n",
        "        print(\"  Accuracy: {0:.2f}\".format(average_valid_accuracy))\n",
        "        print(\"  Validation took: {:}\".format(format_time(timeit.default_timer() - start)))\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"Training complete!!!\")\n",
        "\n",
        "    return train_loss_list, valid_loss_list\n",
        "\n",
        "# Train the Model\n",
        "train_loss_list, valid_loss_list = train_model(model=model,\n",
        "                                               optimizer=optimizer,\n",
        "                                               train_loader=training_dataloader,\n",
        "                                               valid_loader=validation_dataloader,\n",
        "                                               num_epochs=epochs,\n",
        "                                               eval_every=len(training_dataloader) // 4)\n",
        "\n",
        "print(\"Training Loss List:\", train_loss_list)\n",
        "print(\"Validation Loss List:\", valid_loss_list)\n"
      ],
      "metadata": {
        "id": "yaWwsYUWAAn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW\n",
        "import random\n",
        "import numpy as np\n",
        "import timeit\n",
        "import datetime\n",
        "\n",
        "# Assuming you have defined training_dataset, training_mask, training_categories,\n",
        "# validation_dataset, validation_mask, and validation_categories in previous cells\n",
        "\n",
        "# Batch size\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Creating dataloaders\n",
        "training_data = TensorDataset(training_dataset, training_mask, training_categories)\n",
        "training_dataloader = DataLoader(training_data, sampler=RandomSampler(training_data), batch_size=BATCH_SIZE)\n",
        "\n",
        "validation_data = TensorDataset(validation_dataset, validation_mask, validation_categories)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=SequentialSampler(validation_data), batch_size=BATCH_SIZE)\n",
        "\n",
        "# Model and optimizer\n",
        "option_name = \"bert-base-uncased\"\n",
        "model = BertForSequenceClassification.from_pretrained(option_name,\n",
        "                                                      num_labels=13,\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)\n",
        "model.cuda()\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=3e-5,\n",
        "                  eps=1e-8)\n",
        "\n",
        "# Number of training epochs\n",
        "epochs = 4\n",
        "\n",
        "# Helper functions\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, optimizer, train_loader, valid_loader, num_epochs, eval_every):\n",
        "    seed_val = 42\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    running_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    for each_epoch in range(num_epochs):\n",
        "        print('\\n')\n",
        "        print(\"*************** Epoch {:}/{:} ***************\".format(each_epoch+1, num_epochs))\n",
        "        print(\"Training....\")\n",
        "\n",
        "        start = timeit.default_timer()\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        for step, (input_desc_ids, input_mask, input_label) in enumerate(train_loader):\n",
        "            if step % eval_every == 0 and step != 0:\n",
        "                stop = timeit.default_timer()\n",
        "                time_elapsed = format_time(stop - start)\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), time_elapsed))\n",
        "\n",
        "            input_desc_ids = input_desc_ids.to(device)\n",
        "            input_mask = input_mask.to(device)\n",
        "            input_label = input_label.to(device)\n",
        "            model.zero_grad()\n",
        "\n",
        "            outputs = model(input_desc_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=input_mask,\n",
        "                            labels=input_label)\n",
        "\n",
        "            loss = outputs.loss\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        average_train_loss = running_loss / len(train_loader)\n",
        "        train_loss_list.append(average_train_loss)\n",
        "\n",
        "        print('\\n')\n",
        "        print(\"  Average training loss: {0:.2f}\".format(average_train_loss))\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"Validating....\")\n",
        "\n",
        "        start = timeit.default_timer()\n",
        "        model.eval()\n",
        "\n",
        "        valid_accuracy = 0.0\n",
        "        steps_eval = 0\n",
        "\n",
        "        for (input_ids, input_masks, input_labels) in valid_loader:\n",
        "            input_ids = input_ids.to(device)\n",
        "            input_masks = input_masks.to(device)\n",
        "            input_labels = input_labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids,\n",
        "                                token_type_ids=None,\n",
        "                                attention_mask=input_masks)\n",
        "\n",
        "            logits = outputs.logits.detach().cpu().numpy()\n",
        "            label_ids = input_labels.to('cpu').numpy()\n",
        "\n",
        "            temp_accuracy = flat_accuracy(logits, label_ids)\n",
        "            valid_accuracy += temp_accuracy\n",
        "            steps_eval += 1\n",
        "\n",
        "        average_valid_accuracy = valid_accuracy / steps_eval\n",
        "        valid_loss_list.append(average_valid_accuracy)\n",
        "\n",
        "        print(\"  Accuracy: {0:.2f}\".format(average_valid_accuracy))\n",
        "        print(\"  Validation took: {:}\".format(format_time(timeit.default_timer() - start)))\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"Training complete!!!\")\n",
        "\n",
        "    return train_loss_list, valid_loss_list\n",
        "\n",
        "# Train the Model\n",
        "train_loss_list, valid_loss_list = train_model(model=model,\n",
        "                                               optimizer=optimizer,\n",
        "                                               train_loader=training_dataloader,\n",
        "                                               valid_loader=validation_dataloader,\n",
        "                                               num_epochs=epochs,\n",
        "                                               eval_every=len(training_dataloader) // 4)\n",
        "\n",
        "print(\"Training Loss List:\", train_loss_list)\n",
        "print(\"Validation Loss List:\", valid_loss_list)"
      ],
      "metadata": {
        "id": "jTMlXwq2Aaox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uuz3dfKI9c8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF0KeTgOhKJF"
      },
      "source": [
        "## **Testing the Perfomance on the Testing Dataframe**\n",
        "\n",
        "The earlier testing dataset is now read and it is formatted int he same way as the training dataset to be fed to the BERT model in order to predict the product categories. In the following code snippets, first the Product Category encoding is done followed by replicating the same steps involving tokenization and input formatting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_je1DRjvjha"
      },
      "source": [
        "### **Reading the testing dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBYLHCfWYUwJ"
      },
      "source": [
        "test_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eF238KHwr24"
      },
      "source": [
        "### **Encoding the Product Categories**\n",
        "\n",
        "The same encoding that was followed for the training set is done in the code snippet below as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfS6L1WhfWar"
      },
      "source": [
        "test_df['categories']=encoder.fit_transform(test_df['primary_categories'])\n",
        "print(Counter(test_df['categories']))\n",
        "\n",
        "prediction_decoded = encoder.inverse_transform(test_df['categories'])\n",
        "print(Counter(prediction_decoded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQQ8dPYDYX40"
      },
      "source": [
        "test_description = test_df[\"cleaned_desc\"].values\n",
        "test_labels = test_df[\"categories\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PBzb4rAYw0N"
      },
      "source": [
        "#converting into tokens\n",
        "test_ids = []\n",
        "\n",
        "for sentence in test_description:\n",
        "  encoded_sentence = tokenizer.encode(sentence,\n",
        "                                  add_special_tokens = True)\n",
        "\n",
        "  test_ids.append(encoded_sentence)\n",
        "\n",
        "test_ids = pad_sequences(test_ids,\n",
        "                         maxlen=max_len,\n",
        "                        dtype=\"long\",\n",
        "                        truncating=\"post\",\n",
        "                         padding=\"post\")\n",
        "\n",
        "# creating the attention masks\n",
        "attention_masks = []\n",
        "\n",
        "for id in test_ids:\n",
        "  temp_mask = [int(i>0) for i in id]\n",
        "  attention_masks.append(temp_mask)\n",
        "\n",
        "# converting into tensors\n",
        "prediction_inputs = torch.tensor(test_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4aW-gCPaSg3"
      },
      "source": [
        "#creating the Pytorch Dataloader\n",
        "testing_data = TensorDataset(prediction_inputs,\n",
        "                                prediction_masks,\n",
        "                                prediction_labels)\n",
        "\n",
        "testing_dataloader = DataLoader(testing_data,\n",
        "                                   sampler=SequentialSampler(testing_data),\n",
        "                                   batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7JvzNiCjbmi"
      },
      "source": [
        "## **Evaluation Function**\n",
        "\n",
        "Our fine tuned model is now applied to the prepared testing dataset to generate predictions on the same and calculate the accuracy by comparing it to the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJOdhFNUjdj_"
      },
      "source": [
        "def evaluation(model = model,\n",
        "               test_loader = testing_dataloader):\n",
        "\n",
        "  print('Predicting labels for {:,} test descriptions'.format(len(testing_data)))\n",
        "\n",
        "  #initialising the running variables\n",
        "  predictions = []\n",
        "  true_categories = []\n",
        "\n",
        "  #putting the model in avaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  for (test_desc_ids, test_mask, test_label) in test_loader:\n",
        "\n",
        "    # adding the batch variables to the GPU\n",
        "    test_desc_ids = test_desc_ids.to(device)\n",
        "    test_mask = test_mask.to(device)\n",
        "    test_label = test_label.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      #forward pass\n",
        "      #calculating the logit predictions\n",
        "      outputs = model(test_desc_ids,\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask = test_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = test_label.to('cpu').numpy()\n",
        "\n",
        "    # Store predictions and true labels\n",
        "    predictions.extend(list( np.argmax(logits, axis=1).flatten()))\n",
        "    true_categories.extend(list(label_ids.flatten()))\n",
        "\n",
        "  print(\"Evaluation done!!!\")\n",
        "\n",
        "  return true_categories, predictions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T29YYBv_wiYk"
      },
      "source": [
        "true_labels, pred_labels = evaluation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wCNOOt_kG5t"
      },
      "source": [
        "## **Calculating the Evaluation Metrics**\n",
        "\n",
        "Classification Report has been printed and a plot of Training and Validation loss was plotted to get an idea about the accuracy of the model and how well our BERT based model will perform on real world data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBKI3tO_j-Ov"
      },
      "source": [
        "print('Classification Report:')\n",
        "print(classification_report(true_labels, pred_labels))\n",
        "\n",
        "plt.figure(figsize = (10,10))\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "cm = cm / cm.astype(float).sum(axis=1)  # Replace np.float with float\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax, cmap='Blues')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.set_xlabel('Predicted Labels')\n",
        "ax.set_ylabel('True Labels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QUh74UDOyAZ"
      },
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Initialize lists to store loss values (if not already done elsewhere)\n",
        "train_loss_list = []  # Initialize an empty list for training losses\n",
        "valid_loss_list = []  # Initialize an empty list for validation losses\n",
        "\n",
        "# (Presumably you have some training loop where you append loss values to these lists)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(train_loss_list, label=\"train\")\n",
        "plt.plot(valid_loss_list, label=\"validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhDtQerCziFS"
      },
      "source": [
        "## **Variants of BERT**\n",
        "\n",
        "Other BERT based pre-trained models have also been explored such as DistilBERT, RoBERTa and XLNet. In the following code snippets, the already pre trained model is trained and then evaluated using the **eval_model()** function. Some of the other evaluation metrics that have been used are f1 score and accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gzXrSgOEQKv"
      },
      "source": [
        "custom_arguments = {\n",
        "    \"output_dir\": \"outputs/\",\n",
        "    \"cache_dir\": \"cache/\",\n",
        "    \"best_model_dir\": \"outputs/best_model/\",\n",
        "\n",
        "    \"fp16\": False,\n",
        "    \"fp16_opt_level\": \"O1\",\n",
        "    \"max_seq_length\": 128,\n",
        "    \"train_batch_size\": 128,\n",
        "    \"eval_batch_size\": 128,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"num_train_epochs\": 1,\n",
        "    \"weight_decay\": 0,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"adam_epsilon\": 1e-8,\n",
        "    \"warmup_ratio\": 0.06,\n",
        "    \"warmup_steps\": 0,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "    \"do_lower_case\": False,\n",
        "\n",
        "    \"logging_steps\": 50,\n",
        "    \"evaluate_during_training\": False,\n",
        "    \"evaluate_during_training_steps\": 2000,\n",
        "    \"evaluate_during_training_verbose\": False,\n",
        "    \"use_cached_eval_features\": False,\n",
        "    \"save_eval_checkpoints\": True,\n",
        "    \"no_cache\": False,\n",
        "    \"save_model_every_epoch\": True,\n",
        "    \"tensorboard_dir\": None,\n",
        "\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"reprocess_input_data\": True,\n",
        "\n",
        "    \"n_gpu\": 1,\n",
        "    \"silent\": False,\n",
        "    \"use_multiprocessing\": True,\n",
        "\n",
        "    \"wandb_project\": None,\n",
        "    \"wandb_kwargs\": {},\n",
        "\n",
        "    \"use_early_stopping\": True,\n",
        "    \"early_stopping_patience\": 3,\n",
        "    \"early_stopping_delta\": 0,\n",
        "    \"early_stopping_metric\": \"eval_loss\",\n",
        "    \"early_stopping_metric_minimize\": True,\n",
        "\n",
        "    \"manual_seed\": None,\n",
        "    \"encoding\": None,\n",
        "    \"config\": {},\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On9jFT3qdMhT"
      },
      "source": [
        "## **2) Training and Testing on the RoBERTa model, a variant of BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGIrdg6QFNlZ"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjzQqlmp7rEe"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/undersampling_balanced_products.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieGgccmd-U45"
      },
      "source": [
        "print(df.shape)\n",
        "print(df.columns.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHJWl8901W3_"
      },
      "source": [
        "## **Dataset Preparation**\n",
        "\n",
        "In data_preparation() function below, the strings in the categories column are encoded to be a numerical value. Further many of the columns which are not necessary are dropped keeping only the **cleaned_desc** and **labels** column (according to the input parameter requirements of the pre-trained RoBERTa model. The dataset is also split into training and testing datasets in this function itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EoWU5-D79tg"
      },
      "source": [
        "import torchnlp\n",
        "from torchnlp.encoders import LabelEncoder\n",
        "from simpletransformers.model import TransformerModel\n",
        "\n",
        "# number of categories that the products can be divided into has been decided to be 13\n",
        "n_classes = 13\n",
        "\n",
        "def data_preparation(df,\n",
        "                     categories = 'primary_categories', ):\n",
        "\n",
        "  df_temp = df.copy(deep=True)\n",
        "\n",
        "  encoder = LabelEncoder(df[\"primary_categories\"])\n",
        "  temp_list = encoder.batch_encode(df[categories].tolist())\n",
        "  temp_list = temp_list.numpy()\n",
        "  temp_list = [label-1 for label in temp_list]\n",
        "  df_temp['final_categories'] = pd.Series(temp_list)\n",
        "\n",
        "  train_df, test_df = train_test_split(df_temp, test_size=0.15)\n",
        "\n",
        "  return train_df, test_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSRWxOgaGHg3"
      },
      "source": [
        "train_df, test_df = data_preparation(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PMZ9GeyBMWC"
      },
      "source": [
        "**Dropping the unnecessary columns from the training and testing datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Coq6fp3jGxJp"
      },
      "source": [
        "train_df = train_df.drop(['Unnamed: 0', 'product_name', 'brand', 'desc_pol', 'desc_len', 'product_category_tree', 'description', 'primary_categories', 'main_category'],axis=1)\n",
        "test_df = test_df.drop(['Unnamed: 0', 'product_name', 'brand', 'desc_pol', 'desc_len', 'product_category_tree', 'description', 'primary_categories', 'main_category'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP-oSf8FHGew"
      },
      "source": [
        "train_df.reset_index(inplace=True)\n",
        "train_df = train_df.drop(['index'],axis=1)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Kfgt04NHwkX"
      },
      "source": [
        "test_df.reset_index(inplace=True)\n",
        "test_df = test_df.drop(['index'],axis=1)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWEpTuFNBR1r"
      },
      "source": [
        "## **Creating a Transformer Model of type \"roberta\"**\n",
        "\n",
        "The following code snippet creates a Transformer Model for training, evaluation and prediction. As mentioned previously, wthe no of labels in which we are classifying our dataset is 13."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqsuAf3z4E_9"
      },
      "source": [
        "#creating the Transformer Model\n",
        "roberta_model = TransformerModel('roberta', 'roberta-base', num_labels=n_classes, args = custom_arguments, use_cuda=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt3YJk0lB-7p"
      },
      "source": [
        "**Calling the train_model() method to train the RoBERTa Transformer Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1bZUJsq4iag"
      },
      "source": [
        "\n",
        "\n",
        "# Now, train the model\n",
        "roberta_model.train_model(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3B457J0CKWp"
      },
      "source": [
        "**Evaluation of the RoBERTa Model**\n",
        "\n",
        "Other indicator functions are also passed as a parameter to the eval_model() method. We have also calculated the **f1 score** and the **accuracy score** for our model by passing them as arguments in the eval_model() function with the help of scikit-learn library."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# Function to calculate multiclass F1 score\n",
        "def multiclass_f1_score(y_true, y_pred):\n",
        "    return f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Assuming your test DataFrame is named `test_df`\n",
        "# Print the DataFrame columns to verify the column names\n",
        "print(\"Columns in test_df:\", test_df.columns)\n",
        "\n",
        "# Print first few rows to inspect the data\n",
        "print(\"First few rows of test_df:\\n\", test_df.head())\n",
        "\n",
        "# Check and convert labels to integer\n",
        "if 'labels' not in test_df.columns:\n",
        "    raise KeyError(\"'labels' column not found in test_df\")\n",
        "\n",
        "label_mapping = {label: idx for idx, label in enumerate(test_df['labels'].unique())}\n",
        "print(\"Label mapping:\", label_mapping)\n",
        "\n",
        "test_df['labels'] = test_df['labels'].map(label_mapping)\n",
        "if test_df['labels'].isnull().any():\n",
        "    raise ValueError(\"Mapping resulted in NaN values. Please check the label_mapping.\")\n",
        "\n",
        "# Ensure DataFrame has correct column names\n",
        "expected_columns = ['text', 'labels']\n",
        "if not all(column in test_df.columns for column in expected_columns):\n",
        "    raise KeyError(f\"Expected columns {expected_columns} not found in test_df\")\n",
        "\n",
        "# Verify labels are single-dimensional and integers\n",
        "assert test_df['labels'].dtype == int, \"Labels are not integers\"\n",
        "assert test_df['labels'].ndim == 1, \"Labels are not single-dimensional\"\n",
        "\n",
        "# Load your model\n",
        "model = ClassificationModel('roberta', 'path/to/your/model', num_labels=len(label_mapping))\n",
        "\n",
        "# Evaluate the model\n",
        "result, model_outputs, wrong_predictions = model.eval_model(test_df, f1=multiclass_f1_score, acc=accuracy_score)\n",
        "\n",
        "print(result)\n",
        "print(model_outputs)\n",
        "print(wrong_predictions)\n"
      ],
      "metadata": {
        "id": "ZapvDcxAG-ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUkzoCv-57WW"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "def multiclass_f1_score(labels, predictions):\n",
        "      return f1_score(labels, predictions, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-MHElBk5lgQ"
      },
      "source": [
        "result, model_outputs, wrong_predictions = roberta_model.eval_model(test_df, f1 = multiclass_f1_score, acc = accuracy_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JeS7svDDlAE"
      },
      "source": [
        "## **3) Training and Testing on the DistilBERT model, a variant of BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lajPJWgPTFj6"
      },
      "source": [
        "distilbert_model = TransformerModel('bert', 'bert-base-uncased', num_labels=n_classes, args = custom_arguments)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqPIisLvTRcQ"
      },
      "source": [
        "train_df, test_df = data_preparation(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG8RB_-dE2Ou"
      },
      "source": [
        "**Dropping the unnecessary columns from the training and testing datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNplTykRE1Sb"
      },
      "source": [
        "train_df = train_df.drop(['Unnamed: 0', 'product_name', 'brand', 'desc_pol', 'desc_len', 'product_category_tree', 'description', 'primary_categories', 'main_category'],axis=1)\n",
        "test_df = test_df.drop(['Unnamed: 0', 'product_name', 'brand', 'desc_pol', 'desc_len', 'product_category_tree', 'description', 'primary_categories', 'main_category'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9K-2B1qUBq5"
      },
      "source": [
        "train_df.reset_index(inplace=True)\n",
        "train_df = train_df.drop(['index'],axis=1)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG-SgU6cUGzg"
      },
      "source": [
        "test_df.reset_index(inplace=True)\n",
        "test_df = test_df.drop(['index'],axis=1)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7HMPyVvULJd"
      },
      "source": [
        "distilbert_model.train_model(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8EvDn13URGv"
      },
      "source": [
        "result, model_outputs, wrong_predictions = distilbert_model.eval_model(test_df, f1 = multiclass_f1_score, acc = accuracy_score)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buwmc_pmDo5v"
      },
      "source": [
        "## **4) Training and Testing on the XLNet model, a variant of BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaS35yxcUWB-"
      },
      "source": [
        "xlnet_model = TransformerModel('xlnet', 'xlnet-base-cased', num_labels=n_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tydwLADKUjNi"
      },
      "source": [
        "train_df, test_df = data_preparation(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt3CYCDWFj3T"
      },
      "source": [
        "train_df = train_df.drop(['Unnamed: 0', 'product_name', 'brand', 'desc_pol', 'desc_len', 'product_category_tree', 'description', 'primary_categories', 'main_category'],axis=1)\n",
        "test_df = test_df.drop(['Unnamed: 0', 'product_name', 'brand', 'desc_pol', 'desc_len', 'product_category_tree', 'description', 'primary_categories', 'main_category'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW8dZDGNUj2N"
      },
      "source": [
        "train_df.reset_index(inplace=True)\n",
        "train_df = train_df.drop(['index','dropped_columns'],axis=1)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApO7c62RUl_N"
      },
      "source": [
        "test_df.reset_index(inplace=True)\n",
        "test_df = test_df.drop(['index', 'dropped_columns'],axis=1)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TiO_UZjUmde"
      },
      "source": [
        "xlnet_model.train_model(train_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ6erIzWUpKH"
      },
      "source": [
        "result, model_outputs, wrong_predictions = xlnet_model.eval_model(test_df, f1 = multiclass_f1_score, acc = accuracy_score)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7nTWxITJhMB"
      },
      "source": [
        "## **PART 2) Long-Short Term Memory (LSTM) based Model:**\n",
        "\n",
        "In the second part of the notebook, LSTM based Deep Learning model is used to solve the problem of Multiclass Product Categorization. The same undersampled balanced dataset that was used for training and evaluating Tranformer based models has also been used in this part for ease of comparison of the results and the working of the model. This already cleaned and pre processed dataset consists of only those data points that can be categorized in the previously mentioned 13 primary categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Q8G4yipTZf"
      },
      "source": [
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4MM-LqtUtoW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy import data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vHrz2_DjCpB"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdhux1bhX3NG"
      },
      "source": [
        "#seeding the value to make the results reproducable\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrJ41ETRKn2m"
      },
      "source": [
        "## **Reading and PreProcessing the Dataset**\n",
        "\n",
        "This dataset os tokenized with the help of **spacy** tokenizer to meet the requirements before passing into the LSTM Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dNxy95pYAUn"
      },
      "source": [
        "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True, lower = True)\n",
        "LABEL = data.LabelField(dtype = torch.float,batch_first=True, lower = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1otzYa9WYH01"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/undersampling_balanced_products.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxMHvFtAYj_k"
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGdRibPJYm71"
      },
      "source": [
        "fields = [(None, None), (None, None), (None, None), (None, None), (None, None), ('primary_categories',LABEL), (None, None), (None, None), (None, None), ('cleaned_desc', TEXT)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRS-Yf9AZDAd"
      },
      "source": [
        "train_data = data.TabularDataset(path = '/content/drive/MyDrive/Flipkart Product Dataset/undersampling_balanced_products.csv', format = 'csv', fields = fields, skip_header = True)\n",
        "\n",
        "\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByKW6WR1ZOdr"
      },
      "source": [
        "#splitting the dataframe into training, validation and test sets\n",
        "# training set + validation set: 80%, test set: 20%\n",
        "\n",
        "train_data, test_data = train_data.split(split_ratio=0.80,)\n",
        "\n",
        "training_data, validation_data = train_data.split(split_ratio=0.85,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC6vN1aUMEyW"
      },
      "source": [
        "## **Preparation of Input and Output Sequences**\n",
        "\n",
        "The vocabulary is built for the product description which is later then converted into integer sequences. In the following code snippet, we have built the vocabulary and initialized the cleaned description with the pretrained embeddings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC5KfAI6Zu8F"
      },
      "source": [
        "TEXT.build_vocab(training_data,min_freq=3,vectors = 'glove.6B.300d')\n",
        "LABEL.build_vocab(training_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ9KzT4wMyxP"
      },
      "source": [
        "The data is prepared in the form of batches and BucketIterator is used for the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO-7C6ngaGaT"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "#Load an iterator\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((training_data, validation_data),\n",
        "                                                            batch_size = BATCH_SIZE,\n",
        "                                                            sort_key = lambda x: len(x.cleaned_desc),\n",
        "                                                            sort_within_batch=True,\n",
        "                                                            device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qDHm0BcNAWA"
      },
      "source": [
        "## **Defining the Model Architecture**\n",
        "\n",
        "In the following code snippet, we have defined our model architecture to perform the multiclass classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QdUR_V2adbK"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__ (self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "\n",
        "        super().__init__()\n",
        "        #embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        #lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        # dense layer\n",
        "        self.dense = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        # softmax activation function\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "        #packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        #concatinating the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs=self.dense(hidden)\n",
        "        #Final activation function\n",
        "        outputs=self.softmax(dense_outputs)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QaTwN4rOLLA"
      },
      "source": [
        "In the following code snippet, we have defined the hyperparameters and instantiated our LSTM Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSjpLfcAdzVH"
      },
      "source": [
        "vocab_size = len(TEXT.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 32\n",
        "num_output_nodes = 13\n",
        "dropout = 0.2\n",
        "bidirectional = True\n",
        "no_layers = 2\n",
        "\n",
        "lstm_model = LSTMClassifier(vocab_size, embedding_dim, num_hidden_nodes,num_output_nodes, no_layers, bidirectional, dropout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYtTOHgieaCv"
      },
      "source": [
        "import torchtext\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print('The model has {} trainable parameters'.format(count_parameters(lstm_model)))\n",
        "\n",
        "#Initialising the word embeddings with the pretrained embedding\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "lstm_model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLkiF38dPWYL"
      },
      "source": [
        "We have defined the optimizer to be Adam Optimizer and the loss function as CrossEntropyLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkgf4TQXgQKm"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def accuracy(preds, y):\n",
        "    counts = 0\n",
        "    for i in range(preds.shape[0]):\n",
        "      counts += (torch.max(preds[i], 0)[1] == y[i]).float()\n",
        "\n",
        "    return counts/preds.shape[0]\n",
        "\n",
        "#saving the following to the GPU\n",
        "lstm_model = lstm_model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtRiZ-lSPpHe"
      },
      "source": [
        "## **Training the LSTM Model**\n",
        "\n",
        "In the following code snippet, the training phase of the model has been activated along with the dropout layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G2wE8JfiW3P"
      },
      "source": [
        "def train_lstm_model(model = lstm_model,\n",
        "          iterator = train_iterator,\n",
        "          optimizer = optimizer,\n",
        "          criterion = criterion):\n",
        "\n",
        "  # tracking the loss and accuracy for every epoch\n",
        "  epoch_loss = 0\n",
        "  epoch_accuracy = 0\n",
        "\n",
        "  print(\"********* TRAINING STARTED ***************\")\n",
        "\n",
        "  #setting the model in the training phase\n",
        "  model.train()\n",
        "\n",
        "  for batch in iterator:\n",
        "\n",
        "    #resetting the gradients after each iteration\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #retrieving the cleaned description and its categories\n",
        "    description, description_length = batch.cleaned_desc\n",
        "    classes = batch.primary_categories\n",
        "\n",
        "    #saving it on the CPU\n",
        "    description = description.to(device)\n",
        "    classes = classes.type(torch.LongTensor).to(device)\n",
        "\n",
        "    predictions = model(description, description_length).squeeze()\n",
        "\n",
        "    loss = criterion(predictions, classes)\n",
        "    acc = accuracy(predictions, classes)\n",
        "\n",
        "    #backpropagating the loss and computing the gradients\n",
        "    loss.backward()\n",
        "    #updating the parameters and taking a step using the computed gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_accuracy += acc.item()\n",
        "\n",
        "  print(\"********* TRAINING COMPLETED ***************\")\n",
        "  return epoch_loss / (len(iterator)-1), epoch_accuracy / (len(iterator)-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1SagkCxjFE2"
      },
      "source": [
        "train_lstm_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmGjcts1hYbg"
      },
      "source": [
        "## **Evaluating the best LSTM Model**\n",
        "\n",
        "In the following code snippet, similar process as that of training the LSTM model is followed for evaluation. This evaluation is then done in the next code snippets after the model is trained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KirEhvjfRL-d"
      },
      "source": [
        "def evaluate_lstm_model(model = lstm_model,\n",
        "             iterator = valid_iterator,\n",
        "             criterion = criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_accuracy = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch in iterator:\n",
        "\n",
        "      description, description_lengths = batch.cleaned_desc\n",
        "      classes = batch.primary_categories\n",
        "\n",
        "      description = description.to(device)\n",
        "      classes = classes.type(torch.LongTensor).to(device)\n",
        "\n",
        "      predictions = model(description, description_lengths).squeeze()\n",
        "\n",
        "      loss = criterion(predictions, classes)\n",
        "      acc = accuracy(predictions, classes)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_accuracy += acc.item()\n",
        "\n",
        "    return epoch_loss / (len(iterator)-1), epoch_accuracy / (len(iterator)-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhwnERAMhCel"
      },
      "source": [
        "no_epochs = 4\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(no_epochs):\n",
        "\n",
        "    #training the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "\n",
        "    #evaluating the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    #calculating the validation loss for the best model\n",
        "    best_valid_loss = min(valid_loss, best_valid_loss)\n",
        "\n",
        "    print('\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print('\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vr1oDKr1uImI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}